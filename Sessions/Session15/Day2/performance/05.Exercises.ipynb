{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbad7a89-071f-4e63-96cf-635debd310d2",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Search algorithms\n",
    "\n",
    "Let's look at two different kinds of search algorithms: linear and binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b416b2-2f2f-4006-8b02-6393ba0c9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_search(items, desired_item):\n",
    "    for position, item in enumerate(items):\n",
    "        if item == desired_item:\n",
    "            return position\n",
    "\n",
    "    raise ValueError(\"%s was not found in the list.\" % desired_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca7dc5-5088-4677-ab3a-86b34469fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr, x):\n",
    "    low = 0\n",
    "    high = len(arr) - 1\n",
    "    mid = 0\n",
    " \n",
    "    while low <= high:\n",
    " \n",
    "        mid = (high + low) // 2\n",
    " \n",
    "        # If x is greater, ignore left half\n",
    "        if arr[mid] < x:\n",
    "            low = mid + 1\n",
    " \n",
    "        # If x is smaller, ignore right half\n",
    "        elif arr[mid] > x:\n",
    "            high = mid - 1\n",
    " \n",
    "        # means x is present at mid\n",
    "        else:\n",
    "            return mid\n",
    " \n",
    "    # If we reach here, then the element was not present\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c1d7e-096a-4ae5-890f-5402be8fe6a6",
   "metadata": {},
   "source": [
    "Create a Python list with several thousand of random elements. Append the element `10` and shuffle the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e0ade-2a1b-4d11-9f47-bc9cc5e890f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b9bcf8a-059e-44f7-855d-158bfa71136c",
   "metadata": {},
   "source": [
    "Create an optmized array either with Numpy, Pandas, or other library you want to test that contains the same amount of random elements of the previous array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0c23e-2714-4af2-97b2-ed4b0ff2a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82e1451c-b168-4412-b6bb-0a0c99c247f5",
   "metadata": {},
   "source": [
    "Perform a simple bench mark using both arrays and both search methods. What is faster? Does it corresponds with your intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3dc065-f73c-4e8e-aa7b-e0197fe32a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e521c1-47f5-4bc2-9a5a-956af19354ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b50c99-65ea-44c9-8927-0f29c461dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bc238-dd05-46ba-b0aa-e7e38bf706ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5ae640e-c1f0-4528-ab63-329ac2737f39",
   "metadata": {},
   "source": [
    "Print the index where the element was found in each one of the structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72832935-c59a-4562-99f8-4b92ae04a96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b7c40a-0c0e-4153-a8ef-3a70384dda06",
   "metadata": {},
   "source": [
    "Add a new element to the data structures you just created. Append the element `20`, but this time don't suffle the structures. If you perform the same benchmarks what do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eaa9eb-3d63-4f54-b0d3-7c5324cd1e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26431bd1-6245-48f5-80a6-0db20564a2d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Can you infer what's the Big O complexity of the algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13399b-facd-48a7-a15f-7f244bd74fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d5eb1a-9002-4946-8e28-792bf439e615",
   "metadata": {},
   "source": [
    "What are the circunstances in which you should use one or the other kind of search? What are the cases and the specific kinds of arrays in which each search makes the most sense to be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a7fe6-c2ab-4803-a56e-3f8d03627423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f87d915-2500-45a4-ade7-749da9f029bc",
   "metadata": {},
   "source": [
    "## List comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442273a-fecb-4420-8784-48ee81c1c848",
   "metadata": {},
   "source": [
    "Let's test the power of list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383a8da-e53e-4444-b9c2-99668a541a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        \"a\": np.random.randn(1000),\n",
    "        \"b\": np.random.randn(1000),\n",
    "        \"N\": np.random.randint(100, 1000, (1000)),\n",
    "        \"x\": \"x\",\n",
    "    })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423570ae-d5ae-45b1-8abe-58c782bb295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * (x - 1)\n",
    "\n",
    "def integrate_f(a, b, N):\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "\n",
    "    for i in range(N):\n",
    "        s += f(a + i * dx)\n",
    "\n",
    "    return s * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07611a57-ec8f-4d8c-9acb-44365bb55256",
   "metadata": {},
   "source": [
    "Usind the data set and the `integrate_f` function above write a function that uses the `integrate_f` as a `for` loop and another one in the form of a `lambda`. Use `df.apply` to apply the results of your `lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6012357-1220-4a37-8b9f-d829a1500b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e7ead4b-4305-4904-a20c-ef4542c476f2",
   "metadata": {},
   "source": [
    "Now use the `timeit`, `prun -l N`(N is the number of lines you want to have displayed) and `snakevyz` to check the different processing times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25341d45-bda8-4ce0-9798-5052dba0c898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef107dfb-75b9-438b-bccf-385102e12931",
   "metadata": {},
   "source": [
    "## Optimizing Python functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665fac1-349e-4215-a9d0-e67e8fb92d11",
   "metadata": {},
   "source": [
    "Try to optmize the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1febbe1-b11c-4a0f-adbf-49e7c70d9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_count(str):\n",
    "    # Initializing count variable to 0\n",
    "    count = 0\n",
    "      \n",
    "    # Creating a set of vowels\n",
    "    vowel = set(\"aeiouAEIOU\")\n",
    "      \n",
    "    # Loop to traverse the alphabet\n",
    "    # in the given string\n",
    "    for alphabet in str:\n",
    "      \n",
    "        # If alphabet is present\n",
    "        # in set vowel\n",
    "        if alphabet in vowel:\n",
    "            count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bd1d8-d0fe-490a-b2a2-e27f232aa5b9",
   "metadata": {},
   "source": [
    "Use this function as an input for your `vowel_count` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4958f8f3-3445-4a81-9bd4-09eef7a02f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def random_char(y):\n",
    "       return ''.join(random.choice(string.ascii_letters) for x in range(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1524c-3a08-43e3-93fd-49f1ab850f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b192b794-36de-4f16-92fd-0b2ca83e112d",
   "metadata": {},
   "source": [
    "Here's another function you can try:\n",
    "\n",
    "Before starting to code anything and thinking about the tools that were presented in this class, do you have an idea for which tool you could use to optimize the following function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4127cf-71fe-4daf-8c3f-fc7b4cdfae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps_to(stair):\n",
    "    if stair == 1:\n",
    "        return 1\n",
    "    elif stair == 2:\n",
    "        return 2\n",
    "    elif stair == 3:\n",
    "        return 4\n",
    "    else:\n",
    "        return (steps_to(stair - 3)\n",
    "                + steps_to(stair - 2)\n",
    "                + steps_to(stair - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a6eb2-8404-4af1-9ab2-93f138cd76ea",
   "metadata": {},
   "source": [
    "## Numba performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c33b4b-7380-4dfb-b1ad-c1ddd7119337",
   "metadata": {},
   "source": [
    "Numba has to compile your function for the argument types given before it executes the machine code version of your function, this takes time. However, once the compilation has taken place Numba caches the machine code version of your function for the particular types of arguments presented. If it is called again the with same types, it can reuse the cached version instead of having to compile again.\n",
    "\n",
    "A really common mistake when measuring performance is to not account for the above behaviour and to time code once with a simple timer that includes the time taken to compile your function in the execution time.\n",
    "\n",
    "Using the `timeit` module is a way of avoiding this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494ae59-525a-4ee0-a34a-eaefb62d43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c7dee-5d34-4385-adfd-4dd8edc8e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49efded-c5c2-4e42-829b-79553fd7a509",
   "metadata": {},
   "source": [
    "Use the following options to test the code in the next cell:\n",
    "\n",
    "    parallel = True - enable the automatic parallelization of the function.\n",
    "    parallel = True - enable the automatic parallelization of the function.\n",
    "\n",
    "    fastmath = True - enable fast-math behaviour for the function. (If true, fastmath enables the use of otherwise unsafe floating point transforms as described in the LLVM documentation.)\n",
    "\n",
    "These are arguments for the `jit` decorator we saw earlier in the examples.\n",
    "\n",
    "`njit` and `jit(nopython=True` are the same. This means that Numba tries to release the global interpreter lock inside the compiled function. The GIL will only be released if Numba can compile the function in nopython mode, otherwise a compilation warning will be printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808aa26-bf29-462a-816b-46dec8657579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sum(A):\n",
    "    acc = 0.\n",
    "    # without fastmath, this loop must accumulate in strict order\n",
    "    for x in A:\n",
    "        acc += np.sqrt(x)\n",
    "    return acc\n",
    "\n",
    "def do_sum_fast(A):\n",
    "    acc = 0.\n",
    "    # with fastmath, the reduction can be vectorized as floating point\n",
    "    # reassociation is permitted.\n",
    "    for x in A:\n",
    "        acc += np.sqrt(x)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07b0d6-5fb7-46d4-a9f0-0b4065961a8d",
   "metadata": {},
   "source": [
    "# Interacting with I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897868c-cff3-454e-b62e-a4db56e918f1",
   "metadata": {},
   "source": [
    "Let's compare some I/O flows. \n",
    "\n",
    "In the following cells the code to create a dataset using `h5py` was given to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7f11a-bb13-4145-adca-26570f778242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a07bd7-f294-4917-85ed-ccf0f786f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "array = np.random.random(size=(10))\n",
    "h5f = h5py.File('data.h5', 'w')\n",
    "h5f.create_dataset('dataset', data = array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267178e7-0640-4463-8ff2-99833907ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_loaded = h5f['dataset'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f83062-ac46-44ae-beb2-b9564f1ff2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(h5_loaded)):\n",
    "    h5_loaded[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c8900-534f-42b6-a4da-56c07fbffc44",
   "metadata": {},
   "source": [
    "Implement an equivalent dataset to this one, but this time using Python's CSV. If you want also give it a try using Pandas and Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37877941-8a86-4edf-a4e8-2fe531baea00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97984b82-4e42-4d44-9009-86668d82e3e5",
   "metadata": {},
   "source": [
    "Change the parameters in this function, things like the size of `np` array and the operation executed inside the `for` loop, maybe you want to add a transformation to each value of the dataset. Explore how performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713900-a91d-416e-8d94-63e99838833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
