{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9528a8c2",
   "metadata": {},
   "source": [
    "# Code testing and Continuous Integration\n",
    "\n",
    "We are going to automate testing of our code as part of an example continuous integration development workflow. We'll start by installing pytest, writing or modifying some code to test, and we'll finish by setting up a github actions workflow that will run automatically when we push changes to our repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde05b36",
   "metadata": {},
   "source": [
    "## Part 0 Installing pytest\n",
    "\n",
    "To install pytest and pytest-coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75087415",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytest pytest-cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c19ed",
   "metadata": {},
   "source": [
    "## Part 1 Returning to the SDSS Clustering Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a6d7c",
   "metadata": {},
   "source": [
    "### 1a) Computing statistics of cluster center separation\n",
    "\n",
    "Report the minimum, maximum, and average separation between the centers of the clusters you identified in the introduction to software repositories example. Cluster centers/cores are stored in the \"core_sample_indices_\" attribute of most sklearn clustering objects. \n",
    "\n",
    "You will want this to be done in a modular fashion. First compute the separation distance of the cluster centers. Then write separate functions that return the minimum, maximum, and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance():\n",
    "    \n",
    "    # fill this in \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1113d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(distances):\n",
    "    \n",
    "    # fill this in \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c180017",
   "metadata": {},
   "source": [
    "### 1b) Writing a unit test for cluster center separation\n",
    "\n",
    "A good unit test: \n",
    "\n",
    "* Fast\n",
    "* Standalone\n",
    "* Repeatable (deterministic?) \n",
    "* Timely (your test shouldn't take longer than the code to write) \n",
    "\n",
    "For each function you wrote in 2a), write a test function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1471146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pairwise distances\n",
    "\n",
    "# fill this in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distance():\n",
    "    # fill this in\n",
    "    assert dis == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9251518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_average():\n",
    "    # fill this in \n",
    "    assert avg == "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6cff0",
   "metadata": {},
   "source": [
    "## Part 2  Running unit tests in pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb30777",
   "metadata": {},
   "source": [
    "### 2a) Structuring the test file\n",
    "\n",
    "Unfortunately, github actions and pytest require us to convert our jupyter notebooks to python scripts before running CI tests. There are tools to automate this for us, but for now, let's do this by hand. \n",
    "\n",
    "pytest expects your code to be organized according to the following convention - you should have a `file_name.py` and a `test_file_name.py`. Create each. In `file_name.py`, copy the functions for computing cluster distances and statistics. Then, in `test_file_name.py`, copy your unit tests. Be sure to import the methods from `file_name.py` into the test file script. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655dda4",
   "metadata": {},
   "source": [
    "### 2b) Running the unit test and checking coverage\n",
    "\n",
    "Now to run the unit test - just type `pytest` at the command line of your conda virtual environment. \n",
    "\n",
    "To check the coverage (how well your tests cover your code) type `pytest --cov`\n",
    "\n",
    "If your tests do not achieve full coverage of your code, modify your tests accordingly.\n",
    "\n",
    "If your tests achieve complete coverage and your code passes your tests, move to part 3 below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c9f9e",
   "metadata": {},
   "source": [
    "### 2c) Bug fixes\n",
    "\n",
    "If your code fails any of your tests, fix your code now and repeat until your code passes your tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7ca4d",
   "metadata": {},
   "source": [
    "## Part 3 Automating Unit Tests with Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d27ec",
   "metadata": {},
   "source": [
    "### Part 3a) Initial Github Actions Workflow template\n",
    "\n",
    "You should find a partially complete github actions workflow template as a .yml file. Github helpfully provides many template workflows for different languages and use cases, so most of the time, you'll just need to fill in the details of an existing workflow. \n",
    "\n",
    "\n",
    "### Part 3b) Fill in when you want the tests to run so that the code runs on a push or pull_request to your working branches and main\n",
    "\n",
    "### Part 3c) make sure that dependencies are properly installed on the virtual machine (\"runner\") that will execute your tests. Up to this point, you should have very minimal dependencies, but for yesterday's SDSS clustering project, you may have more complicated ones. If you have a requirements.txt file in your github directory, you can install dependencies with `pip install -r requirements.txt` - there are many ways to produce a requirements file, but I might start by trying `pip freeze > requirements.txt` within your virtual environment.\n",
    "\n",
    "### Part 3d) Now push to your main branch and check for errors. Fix any that occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa06db3",
   "metadata": {},
   "source": [
    "## Part 4 Complete Workflow\n",
    "\n",
    "In this part, work with your partner to adapt yesterday's example clustering problem to the full git collaborative and test-driven workflow. Open Issues for features you want to include, design tests for those features, implement them, make simultaneous changes to the clustering implementation, make push/pull requests, and automate unit testing of your code. Alternatively, get an early start on a problem you might work on in the hackathon by creating a repository, writing some code, and executing unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
