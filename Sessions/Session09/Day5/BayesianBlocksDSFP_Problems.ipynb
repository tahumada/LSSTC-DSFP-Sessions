{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import astroquery\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building Histograms with Bayesian Priors\n",
    "## An Introduction to Bayesian Blocks\n",
    "========\n",
    "\n",
    "#### Version 0.1\n",
    "\n",
    "***\n",
    "By LM Walkowicz 2019 June 14\n",
    "\n",
    "*This notebook makes heavy use of Bayesian block implementations by Jeff Scargle, Jake VanderPlas, Jan Florjanczyk, and the Astropy team.*\n",
    "\n",
    "Before you begin, [please download the dataset](https://northwestern.box.com/s/d5cifl4zgwcl1j22ue7w5hgrsqabfrsx) for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 1) Histograms Lie!\n",
    "\n",
    "One of the most common and useful tools for data visualization can be incredibly misleading. Let's revisit how.\n",
    "\n",
    "![ChessUrl](https://media.giphy.com/media/EouEzI5bBR8uk/giphy.gif \"chess\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 1a**\n",
    "\n",
    "First, let's make some histograms! Below, I provide some data; please make a histogram of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "np.random.seed(0)\n",
    "x = np.concatenate([stats.cauchy(-5, 1.8).rvs(500),\n",
    "                    stats.cauchy(-4, 0.8).rvs(2000),\n",
    "                    stats.cauchy(-1, 0.3).rvs(500),\n",
    "                    stats.cauchy(2, 0.8).rvs(1000),\n",
    "                    stats.cauchy(4, 1.5).rvs(500)])\n",
    "\n",
    "# truncate values to a reasonable range\n",
    "x = x[(x > -15) & (x < 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "# plt.hist( \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Hey, nice histogram!** \n",
    "\n",
    "But how do we know we have visualized all the relevant structure in our data? \n",
    "\n",
    "*Play around with the binning and consider: \n",
    "What features do you see in this data? Which of these features are important?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "# plt.hist \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 1b**\n",
    "\n",
    "What are some issues with histograms? \n",
    "\n",
    "*Take a few min to discuss this with your partner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Solution 1b**\n",
    "\n",
    "*write your solution here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 1c**\n",
    "\n",
    "We have previously covered a few ways to make histograms better. What are some ways you could improve your histogram?\n",
    "\n",
    "*Take a few min to discuss this with your partner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 1d**\n",
    "\n",
    "There are lots of ways to improve the previous histogram-- let's implement a KDE representation instead! As you have seen in previous sessions, we will borrow a bit of code from Jake VanderPlas to estimate the KDE. \n",
    "\n",
    "As a reminder, you have a number of choices of kernel in your KDE-- some we have used in the past: tophat, Epanechnikov, Gaussian. Please plot your original histogram, and then overplot a few example KDEs on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def kde_sklearn(data, grid, bandwidth = 1.0, **kwargs):\n",
    "    kde_skl = KernelDensity(bandwidth = bandwidth, **kwargs)\n",
    "    kde_skl.fit(data[:, np.newaxis])\n",
    "    log_pdf = kde_skl.score_samples(grid[:, np.newaxis]) # sklearn returns log(density)\n",
    "\n",
    "    return np.exp(log_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "# plt.hist( \n",
    "# grid = \n",
    "# PDF = \n",
    "# plt.plot("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 1d**\n",
    "\n",
    "Which parameters most affected the shape of the final distribution?\n",
    "\n",
    "What are some possible issues with using a KDE representation of the data?\n",
    "\n",
    "*Discuss with your partner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Solution 1d**\n",
    "\n",
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 2) Histograms Episode IV: A New Hope \n",
    "\n",
    "How can we create representations of our data that are robust against the known issues with histograms and KDEs?\n",
    "\n",
    "![ChessUrl](https://media.giphy.com/media/DrL54YGfFb5Bu/giphy.gif \"leia\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Introducing: Bayesian Blocks**\n",
    "\n",
    "We want to represent our data in the most general possible way, a method that\n",
    "* avoids assumptions about smoothness or shape of the signal (which might place limitations on scales and resolution)\n",
    "* is nonparametric (doesn't fit some model)\n",
    "* finds and characterizes local structure in our time series (in contrast to periodicities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(continued)\n",
    "\n",
    "* handles arbitrary sampling (i.e. doesn't require evenly spaced samples, doesn't care about sparse samples)\n",
    "* is as hands-off as possible-- user interventions should be minimal or non-existent \n",
    "* is applicable to multivariate data\n",
    "* can both analyze data after they are collected, and in real time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Blocks works by creating a super-simple representation of the data, essentially a piecewise fit that segments our time series. \n",
    "\n",
    "In the implementations we will use today, the model is a piecewise linear fit in time across each individual bin, or \"block\". \n",
    "one modeling the signal as linear in time across the block:\n",
    "$$x(t) = λ(1 + a(t − t_{fid}))$$ \n",
    "\n",
    "where $\\lambda$ is the signal strength at the fiducial time $t_{fid}$, and the coefficient $a$ determines the rate of change over the block. \n",
    "\n",
    "Scargle et al. (2012) point out that using a linear fit is good because it makes calculating the fit really easy, but you could potentially use something more complicated (they provide some details for using an exponential model, $x(t) = λe^{a(t−t_{fid}})$, in their Appendix C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The Fitness Function**\n",
    "\n",
    "![](https://media.giphy.com/media/sLs8Ll8Qx51xm/giphy.gif \"fitness\")\n",
    "\n",
    "The insight in Bayesian Blocks is that you can use a Bayesian likelihood framework to compute a \"fitness function\" that depends only on the number and size of the blocks. \n",
    "\n",
    "In every block, you are trying to maximize some goodness-of-fit measure for data in that individual block. This fit depends *only* on the data contained in its block, and is independent of all other data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal segmentation of the time series, then, is the segmentation that maximizes fitness-- the *total* goodness-of-fit over *all* the blocks (so for example, you could use the sum over all blocks of whatever your quantitative expression is for the goodness of fit in individual blocks). \n",
    "![](https://media.giphy.com/media/5YtiXID98BjAESGkn9/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The entire time series is then represented by a series of segments (blocks) characterized by very few parameters:\n",
    "\n",
    "* $N_{cp}$: the number of change-points\n",
    "\n",
    "* $t_{k}^{cp}$: the change-point starting block k\n",
    "\n",
    "* $X_k$: the signal amplitude in block k\n",
    "\n",
    "for k = 1, 2, ... $N_{cp}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When using Bayesian Blocks (particularly on time series data) we often speak of \"change points\" rather than segmentation, as the block edges essentially tell us the discrete times at which a signal’s statistical properties change discontinuously, though the segments themselves are constant between these points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**You looking at KDEs right now:**\n",
    "![ChessUrl](https://media.giphy.com/media/MpmrNx3scJrPy/giphy.gif \"meangirls\")\n",
    "\n",
    "In some cases (such as some of the examples below), the Bayesian Block representation may look kind of clunky. *HOWEVER*: remember that histograms and KDEs may sometimes look nicer, but can be really misleading! If you want to derive *physical insight* from these representations of your data, Bayesian Blocks can provide a means of deriving physically interesting quantities (for example, better estimates of event locations, lags, amplitudes, widths, rise and decay times, etc). \n",
    "\n",
    "On top of that, you can do all of the above without losing or hiding information via smoothing or other model assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**HOW MANY BLOCKS, THO?!**\n",
    "\n",
    "We began this lesson by bemoaning that histograms force us to choose a number of bins, and that KDEs require us to choose a bandwidth. Furthermore, one of the requirements we had for a better way forward was that the user interaction be minimal or non-existent. What to do?\n",
    "\n",
    "Bayesian Blocks works by defining a prior distribution for the number of blocks, such that a single parameter controls the steepness of this prior (in other words, the relative probability for smaller or larger numbers of blocks. \n",
    "\n",
    "Once this prior is defined, the size, number, and locations of the blocks are determined solely and uniquely by the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**So, what does the prior look like?**\n",
    "\n",
    "In most cases, $N_{blocks}$ << N (you are, after all, still binning your data-- if $N_{blocks}$ was close to N, you wouldn't really be doing much). Scargle et al. (2012) adopts a geometric prior (Coram 2002), which assigns smaller probability to a large number of blocks:\n",
    "\n",
    "$$P(N_{blocks}) = P_{0}\\gamma N_{blocks}$$\n",
    "\n",
    "for $0 ≤ N_{blocks} ≤ N$, and zero otherwise since $N_{blocks}$ cannot be negative or larger than the number of data cells. \n",
    "\n",
    "Substituting in the normalization constant $P_{0}$ gives\n",
    "\n",
    "$$P(N_{blocks}) = \\frac{1−\\gamma}{1-\\gamma^{N+1}}\\gamma^{N_{blocks}}$$\n",
    "\n",
    "<sub>Essentially, this prior says that finding k + 1 blocks is less likely than finding k blocks by the constant factor $\\gamma$. Scargle (2012) also provides a nice intuitive way of thinking about $\\gamma$: $\\gamma$ is adjusting the amount of structure in the resulting representation.</sub>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The Magic Part**\n",
    "\n",
    "At this point, you may be wondering about how the algorithm is capable of finding an *optimal* number of blocks. As Scargle et al (2012) admits\n",
    ">the number of possible partitions (i.e. the number of ways N cells can be arranged in blocks) is $2^N$. This number is exponentially large, rendering an explicit exhaustive search of partition space utterly impossible for all but very small N.\n",
    "\n",
    "![](https://media.giphy.com/media/MIY4jpusckRmU/giphy.gif \"cookiebored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In his blog post on Bayesian Blocks, Jake VdP compares the algorithm's use of *dynamic programming* to mathematical induction. For example: how could you prove that  \n",
    "\n",
    "$$1 + 2 + \\cdots + n = \\frac{n(n+1)}{2}$$\n",
    "\n",
    "is true for all positive integers $n$? An inductive proof of this formula proceeds in the following fashion:\n",
    "\n",
    "**Base Case**: We can easily show that the formula holds for $n = 1$.\n",
    "\n",
    "**Inductive Step**: For some value $k$, assume that $1 + 2 + \\cdots + k = \\frac{k(k+1)}{2}$ holds. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Adding $(k + 1)$ to each side and rearranging the result yields \n",
    "\n",
    "$$1 + 2 + \\cdots + k + (k + 1) = \\frac{(k + 1)(k + 2)}{2}$$\n",
    "\n",
    "Looking closely at this, we see that we have shown the following: if our formula is true for $k$, then it must be true for $k + 1$.\n",
    "\n",
    "By 1 and 2, we can show that the formula is true for any positive integer $n$, simply by starting at $n=1$ and repeating the inductive step $n - 1$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the Bayesian Blocks algorithm, one can find the optimal binning for a single data point; so by analogy with our example above (full details are given in the Appendix of Scargle et al. 2012), if you can find the optimal binning for $k$ points, it's a short step to the optimal binning for $k + 1$ points. \n",
    "\n",
    "So, rather than performing an exhaustive search of all possible bins, which would scale as $2^N$, the time to find the optimal binning instead scales as $N^2$.\n",
    "\n",
    "![](https://media.giphy.com/media/12NUbkX6p4xOO4/giphy.gif \"shia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Playing with Blocks**\n",
    "\n",
    "We will begin playing with (Bayesian) blocks with a simple implementation, outlined by Jake VanderPlas in this blog: https://jakevdp.github.io/blog/2012/09/12/dynamic-programming-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "\n",
    "def bayesian_blocks(t):\n",
    "    \"\"\"Bayesian Blocks Implementation\n",
    "\n",
    "    By Jake Vanderplas.  License: BSD\n",
    "    Based on algorithm outlined in http://adsabs.harvard.edu/abs/2012arXiv1207.5578S\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : ndarray, length N\n",
    "        data to be histogrammed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bins : ndarray\n",
    "        array containing the (N+1) bin edges\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is an incomplete implementation: it may fail for some\n",
    "    datasets.  Alternate fitness functions and prior forms can\n",
    "    be found in the paper listed above.\n",
    "    \"\"\"\n",
    "    # copy and sort the array\n",
    "    t = np.sort(t)\n",
    "    N = t.size\n",
    "\n",
    "    # create length-(N + 1) array of cell edges\n",
    "    edges = np.concatenate([t[:1],\n",
    "                            0.5 * (t[1:] + t[:-1]),\n",
    "                            t[-1:]])\n",
    "    block_length = t[-1] - edges\n",
    "\n",
    "    # arrays needed for the iteration\n",
    "    nn_vec = np.ones(N)\n",
    "    best = np.zeros(N, dtype=float)\n",
    "    last = np.zeros(N, dtype=int)\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "    # Start with first data cell; add one cell at each iteration\n",
    "    #-----------------------------------------------------------------\n",
    "    for K in range(N):\n",
    "        # Compute the width and count of the final bin for all possible\n",
    "        # locations of the K^th changepoint\n",
    "        width = block_length[:K + 1] - block_length[K + 1]\n",
    "        count_vec = np.cumsum(nn_vec[:K + 1][::-1])[::-1]\n",
    "\n",
    "        # evaluate fitness function for these possibilities\n",
    "        fit_vec = count_vec * (np.log(count_vec) - np.log(width))\n",
    "        fit_vec -= 4  # 4 comes from the prior on the number of changepoints\n",
    "        fit_vec[1:] += best[:K]\n",
    "\n",
    "        # find the max of the fitness: this is the K^th changepoint\n",
    "        i_max = np.argmax(fit_vec)\n",
    "        last[K] = i_max\n",
    "        best[K] = fit_vec[i_max]\n",
    "    \n",
    "    #-----------------------------------------------------------------\n",
    "    # Recover changepoints by iteratively peeling off the last block\n",
    "    #-----------------------------------------------------------------\n",
    "    change_points =  np.zeros(N, dtype=int)\n",
    "    i_cp = N\n",
    "    ind = N\n",
    "    while True:\n",
    "        i_cp -= 1\n",
    "        change_points[i_cp] = ind\n",
    "        if ind == 0:\n",
    "            break\n",
    "        ind = last[ind - 1]\n",
    "    change_points = change_points[i_cp:]\n",
    "\n",
    "    return edges[change_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 2a** \n",
    "\n",
    "Let's visualize our data again, but this time we will use Bayesian Blocks.\n",
    "\n",
    "Plot a standard histogram (as above), but now plot the Bayesian Blocks representation of the distribution over it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# complete \n",
    "plt.hist("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 2b**\n",
    "\n",
    "How is the Bayesian Blocks representation different or similar? \n",
    "\n",
    "How might your choice of representation affect your scientific conclusions about your data? \n",
    "\n",
    "*Take a few min to discuss this with your partner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you are using histograms for analysis, you might infer physical meaning from the presence or absence of features in these distributions. As it happens, histograms of time-tagged event data are often used to characterize physical events in time domain astronomy, for example gamma ray bursts or stellar flares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 3) Bayesian Blocks in the wild\n",
    "\n",
    "Now we'll apply Bayesian Blocks to some real astronomical data, and explore how our visualization choices may affect our scientific conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's get some data!\n",
    "\n",
    "All data from NASA missions is hosted on the Mikulski Archive for Space Telescopes (aka MAST). As an aside, the M in MAST used to stand for \"Multimission\", but was changed to honor Sen. Barbara Mikulski (D-MD) for her tireless support of science. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some MAST data (mostly the original data products) can be directly accessed using astroquery (there's an extensive guide to interacting with MAST via astroquery here: https://astroquery.readthedocs.io/en/latest/mast/mast.html). \n",
    "\n",
    "In addition, MAST also hosts what are called \"Higher Level Science Products\", or HLSPs, which are data derived by science teams in the course of doing their analyses. You can see a full list of HLSPs here: https://archive.stsci.edu/hlsp/hlsp-table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These data tend to be more heterogeneous, and so are not currently accessible through astroquery (for the most part). They will be added in the future. But never fear! You can also submit SQL queries via MAST's CasJobs interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Go to the MAST CasJobs http://mastweb.stsci.edu/mcasjobs/home.aspx\n",
    "\n",
    "If I have properly remembered to tell you to create a MAST CasJobs login, you can login now (and if not, just go ahead and sign up now, it's fast)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will be working with the table of new planet radii by Berger et al. (2019). \n",
    "*If you like, you can check out the paper here! https://arxiv.org/pdf/1805.00231.pdf*\n",
    "\n",
    "From the \"Query\" tab, select \"HLSP_KG_RADII\" from the Context drop-down menu. \n",
    "\n",
    "You can then enter your query. In this example, we are doing a simple query to get all the KG-RADII radii and fluxes from the exoplanets catalog, which you could use to reproduce the first figure, above. For short queries that can execute in less than 60 seconds, you can hit the \"Quick\" button and the results of your query will be displayed below, where you can export them as needed. For longer queries like this one, you can select into an output table (otherwise a default like MyDB.MyTable will be used), hit the \"Submit\" button, and when finished your output table will be available in the MyDB tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3a**\n",
    "\n",
    "Write a SQL query to fetch this table from MAST using CasJobs.\n",
    "\n",
    "Your possible variables are KIC_ID, KOI_ID, Planet_Radius, Planet_Radius_err_upper, Planet_Radius_err_lower, Incident_Flux, Incident_Flux_err_upper, Incident_Flux_err_lower, AO_Binary_Flag\n",
    "\n",
    "For very short queries you can use \"Quick\" for your query; this table is large enough that you should use \"Submit\".\n",
    "\n",
    "*Hint: You will want to SELECT some stuff FROM a table called exoplanet_parameters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Solution 3a**\n",
    "\n",
    "*Write your SQL query here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once your query has completed, you will go to the MyDB tab to see the tables you have generated (in the menu at left). From here, you can click on a table, and select Download. I would recommend downloading your file as a CSV (comma-separated value) file, as CSV are simple, and can easily read into python via a variety of methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3b**\n",
    "\n",
    "Time to read in the data! There are several ways of importing a csv into python... choose your favorite and load in the table you downloaded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3c**\n",
    "\n",
    "Let's look at the distribution of the small planet radii in this table, which are given in units of Earth radii. Select the planets whose radii are Neptune-sized or smaller. \n",
    "\n",
    "Select the planet radii for all planets smaller than Neptune in the table, and visualize the distribution of planet radii using a standard histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3d**\n",
    "\n",
    "What features do you see in the histogram of planet radii? Which of these features are important? \n",
    "\n",
    "*Discuss with your partner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Solution 3d**\n",
    "\n",
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3e**\n",
    "\n",
    "Now let's try visualizing these data using Bayesian Blocks. Please recreate the histogram you plotted above, and then plot the Bayesian Blocks version over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3f**\n",
    "\n",
    "What features do you see in the histogram of planet radii? Which of these features are important? \n",
    "\n",
    "*Discuss with your partner.*\n",
    "\n",
    "*Hint: maybe you should look at some of the comments in the implementation of Bayesian Blocks we are using*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Solution 3f**\n",
    "\n",
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "OK, so in this case, the Bayesian Blocks representation of the data looks fairly different. A couple things might stand out to you:\n",
    "* There are large spikes in the Bayesian Blocks representation that are not present in the standard histogram\n",
    "* If we're just looking at the Bayesian Block representation, it's not totally clear whether one should believe that there are two peaks in the distribution. \n",
    "\n",
    "**HMMMMMmmmm....**\n",
    "\n",
    "Wait! Jake VDP told us to watch out for this implementation. Maybe we should use something a little more official instead...\n",
    "\n",
    "GOOD NEWS~! There is a Bayesian Blocks implementation included in astropy. Let's try that. \n",
    "http://docs.astropy.org/en/stable/api/astropy.stats.bayesian_blocks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Important note**\n",
    "\n",
    "There is a known issue in the astropy implementation of Bayesian Blocks; see: https://github.com/astropy/astropy/issues/8317\n",
    "\n",
    "It is possible this issue will be fixed in a future release, but in the event this problem arises for you, you will need to edit bayesian_blocks.py to include the following ```else``` statement (see issue link above for exact edit):\n",
    "\n",
    " ```if self.ncp_prior is None:\n",
    "            ncp_prior = self.compute_ncp_prior(N)\n",
    " else:\n",
    "            ncp_prior = self.ncp_prior```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import astropy.stats.bayesian_blocks as bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 3g**\n",
    "\n",
    "Please repeat the previous problem, but this time use the astropy implementation of Bayesian Blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Putting these results in context**\n",
    "\n",
    "Both standard histograms and KDEs can be useful for quickly visualizing data, and in some cases, getting an intuition for the underlying PDF of your data.\n",
    "\n",
    "However, keep in mind that they both involve making parameter choices that are largely not motivated in any quantitative way. These choices can create wildly misleading representations of your data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "In particular, your choices may lead you to make a physical interpretation that may or may not be correct (in our example, bear in mind that the observed distribution of exoplanetary radii informs models of planet formation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Bayesian Blocks is more than just a variable-width histogram**\n",
    "\n",
    "While KDEs often do a better job of visualizing data than standard histograms do, they also create a loss of information. Philosophically speaking, what Bayesian Blocks do is posit that the \"change points\", also known as the bin edges, contain information that is interesting. When you apply a KDE, you are smoothing your data by creating an approximation, and that can mean you are losing potential insights by removing information. \n",
    "\n",
    "While Bayesian Blocks are useful as a replacement for histograms in general, their ability to identify change points makes them especially useful for time series analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 4) Bayesian Blocks for Time Series Analysis\n",
    "\n",
    "While Bayesian Blocks can be very useful as a simple replacement for histograms, one of its great strengths is in finding \"change points\" in time series data. Finding these change points can be useful for discovering interesting events in time series data you already have, *and* it can be used in real-time to detect changes that might trigger another action (for example, follow up observations for LSST). \n",
    "\n",
    "![](https://media.giphy.com/media/l0MYOUI5XfRk4LLWM/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at a few examples of using Bayesian Blocks in the time series context. \n",
    "\n",
    "First and foremost, it's important to understand the different between various kinds of time series data. \n",
    " \n",
    "**Event data** come from photon counting instruments. In these data, the time series typically consists of photon arrival times, usually in a particular range of energies that the instrument is sensitive to. Event data are univariate, in that the time series is \"how many photons at a given time\", or \"how many photons in a given chunk of time\". \n",
    "\n",
    "**Point measurements** are measurements of a (typically) continuous source at a given moment in time, often with some uncertainty associated with the measurement. These data are multivariate, as your time series relates time, your measurement (e.g. flux, magnitude, etc) and its associated uncertainty to one another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 4a**\n",
    "\n",
    "Let's look at some event data from BATSE, a high energy astrophysics experiment that flew on NASA's Compton Gamma-Ray Observatory. BATSE primarily studied gamma ray bursts (GRBs), capturing its detections in four energy channels: ~25-55 keV, 55-110 keV, 110-320 keV, and >320 keV.\n",
    "\n",
    "You have been given four text files that record one of the BATSE GRB detections. Please read these data in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 4b**\n",
    "\n",
    "When you reach this point, you and your partner should pick a number between 1 and 4; your number is the channel whose data you will work with. \n",
    "\n",
    "Using the data for your channel, please visualize the photon events in both a standard histogram and using Bayesian Blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 4c**\n",
    "\n",
    "Let's take a moment to reflect on the differences between these two representations of our data. \n",
    "\n",
    "Please discuss with your partner:\n",
    "* How many bursts are present in these two representations? \n",
    "* How accurately would you be able to identify the time of the burst(s) from these representations? What about other quantities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**For the groups who worked with Channel 3:**\n",
    "\n",
    "You may have noticed very sharp features in your blocks representation of the data. Are they real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To quote Jake VdP:\n",
    "\n",
    ">Simply put, there are spikes because the piecewise constant likelihood model says that spikes are favored. By saying that the spikes seem unphysical, you are effectively adding a prior on the model based on your intuition of what it should look like.\n",
    "\n",
    "To quote Jeff Scargle:\n",
    "\n",
    ">Trust the algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 5: Finding flares \n",
    "\n",
    "As we have just seen, Bayesian Blocks can be very useful for finding transient events-- it worked great on our photon counts from BATSE! Let's try it on some slightly more complicated data: lightcurves from NASA's Kepler mission. Kepler's data consists primarily of point measures (rather than events)-- a Kepler lightcurve is just the change in the brightness of the star over time (with associated uncertainties).  \n",
    "![](https://media.giphy.com/media/2A5feTniPI48M/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 5a**\n",
    "\n",
    "People often speak of transients (like the GRB we worked with above) and variables (like RR Lyrae or Cepheid stars) as being two completely different categories of changeable astronomical objects. However, some objects exhibit both variability *and* transient events. Magnetically active stars are one example of these objects: many of them have starspots that rotate into and out of view, creating periodic (or semi-periodic) variability, but they also have flares, magnetic reconnection events that create sudden, rapid changes in the stellar brightness. \n",
    "\n",
    "A challenge in identifying flares is that they often appear against a background that is itself variable. While their are many approaches to fitting both quiescent and flare variability (Gaussian processes, which you saw earlier this week, are often used for exactly this purpose!), they can be very time consuming. \n",
    "\n",
    "Let's read in some data, and see whether Bayesian Blocks can help us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# execute this cell\n",
    "kplr_hdul = fits.open('./data/kplr009726699-2011271113734_llc.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cool, we have loaded in the FITS file. Let's look at what's in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ./data/kplr009726699-2011271113734_llc.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      58   ()      \n",
      "  1  LIGHTCURVE    1 BinTableHDU    161   4573R x 20C   ['D', 'E', 'J', 'E', 'E', 'E', 'E', 'E', 'E', 'J', 'D', 'E', 'D', 'E', 'D', 'E', 'D', 'E', 'E', 'E']   \n",
      "  2  APERTURE      1 ImageHDU        48   (11, 13)   int32   \n"
     ]
    }
   ],
   "source": [
    "# execute this cell\n",
    "kplr_hdul.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want the light curve, so let's check out what's in that part of the file!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColDefs(\n",
       "    name = 'TIME'; format = 'D'; unit = 'BJD - 2454833'; disp = 'D14.7'\n",
       "    name = 'TIMECORR'; format = 'E'; unit = 'd'; disp = 'E13.6'\n",
       "    name = 'CADENCENO'; format = 'J'; disp = 'I10'\n",
       "    name = 'SAP_FLUX'; format = 'E'; unit = 'e-/s'; disp = 'E14.7'\n",
       "    name = 'SAP_FLUX_ERR'; format = 'E'; unit = 'e-/s'; disp = 'E14.7'\n",
       "    name = 'SAP_BKG'; format = 'E'; unit = 'e-/s'; disp = 'E14.7'\n",
       "    name = 'SAP_BKG_ERR'; format = 'E'; unit = 'e-/s'; disp = 'E14.7'\n",
       "    name = 'PDCSAP_FLUX'; format = 'E'; unit = 'e-/s'; disp = 'E14.7'\n",
       "    name = 'PDCSAP_FLUX_ERR'; format = 'E'; unit = 'e-/s'; disp = 'E14.7'\n",
       "    name = 'SAP_QUALITY'; format = 'J'; disp = 'B16.16'\n",
       "    name = 'PSF_CENTR1'; format = 'D'; unit = 'pixel'; disp = 'F10.5'\n",
       "    name = 'PSF_CENTR1_ERR'; format = 'E'; unit = 'pixel'; disp = 'E14.7'\n",
       "    name = 'PSF_CENTR2'; format = 'D'; unit = 'pixel'; disp = 'F10.5'\n",
       "    name = 'PSF_CENTR2_ERR'; format = 'E'; unit = 'pixel'; disp = 'E14.7'\n",
       "    name = 'MOM_CENTR1'; format = 'D'; unit = 'pixel'; disp = 'F10.5'\n",
       "    name = 'MOM_CENTR1_ERR'; format = 'E'; unit = 'pixel'; disp = 'E14.7'\n",
       "    name = 'MOM_CENTR2'; format = 'D'; unit = 'pixel'; disp = 'F10.5'\n",
       "    name = 'MOM_CENTR2_ERR'; format = 'E'; unit = 'pixel'; disp = 'E14.7'\n",
       "    name = 'POS_CORR1'; format = 'E'; unit = 'pixels'; disp = 'E14.7'\n",
       "    name = 'POS_CORR2'; format = 'E'; unit = 'pixels'; disp = 'E14.7'\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute this cell\n",
    "lcdata = kplr_hdul[1].data\n",
    "lcdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# execute this cell \n",
    "\n",
    "t = lcdata['TIME']\n",
    "f = lcdata['PDCSAP_FLUX']\n",
    "e = lcdata['PDCSAP_FLUX_ERR']\n",
    "t = t[~np.isnan(f)]\n",
    "e = e[~np.isnan(f)]\n",
    "f = f[~np.isnan(f)]\n",
    "nf = f / np.median(f)\n",
    "ne = e / np.median(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 5b**\n",
    "\n",
    "Use a scatter plot to visualize the Kepler lightcurve. I strongly suggest you try displaying it at different scales by zooming in (or playing with the axis limits), so that you can get a better sense of the shape of the lightcurve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 5c**\n",
    "\n",
    "These data consist of a variable background, with occasional bright points caused by stellar flares.\n",
    "\n",
    "Brainstorm possible approaches to find the flare events in this data. Write down your ideas, and discuss their potential advantages, disadvantages, and any pitfalls that you think might arise. \n",
    "\n",
    "*Discuss with your partner*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Solution 5c**\n",
    "\n",
    "*Write your notes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are lots of possible ways to approach this problem. In the literature, a very common traditional approach has been to fit the background variability while ignoring the outliers, then to subtract the background fit, and flag any point beyond some threshold value as belonging to a flare. More sophisticated approaches also exist, but they are often quite time consuming (and in many cases, detailed fits require a good starting estimate for the locations of flare events). \n",
    "\n",
    "Recall, however, that Bayesian Blocks is particularly effective at identifying change points in our data. Let's see if it can help us in this case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Problem 5d**\n",
    "\n",
    "Use Bayesian Blocks to visualize the Kepler lightcurve. Note that you are now using data that consists of point measurements, rather than event data (as for the BATSE example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "\n",
    "edges = \n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "plt.step("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concluding Remarks \n",
    "\n",
    "As you can see, using Bayesian Blocks allowed us to represent the data, including both quiescent variability and flares, without having to smooth, clip, or otherwise alter the data. \n",
    "\n",
    "One potential drawback here is that the change points don't identify the flares themselves, or at least don't identify them as being different from the background variability-- the algorithm identifies change points, but does not know anything about what change points might be interesting to you in particular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another potential drawback is that it is possible that the Bayesian Block representation may not catch all events, or at least may not, on its own, provide an unambiguous sign that a subtle signal of interest is in the data.\n",
    "\n",
    "In these cases, it is sometimes instructive to use a hybrid approach, where one combines the bins determined from a traditional histogram with the Bayesian Blocks change points. Alternatively, if one has a good model for the background, one can compared the blocks representation of a background-only simulated data set with one containing both background and model signal. \n",
    "\n",
    "Further interesting examples (in the area of high energy physics and astrophysics) are provided by this paper:\n",
    "https://arxiv.org/abs/1708.00810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenge Problem\n",
    "\n",
    "Bayesian Blocks is so great! However, there are occasions in which it doesn't perform all that well-- particularly when there are large numbers of repeated values in the data. Jan Florjanczyk, a senior data scientist at Netflix, has written up a description of the problem, and implemented a version of Bayesian Blocks that does a better job on data with repeating values. Read his blog post on \"Stratfied Bayesian Blocks\" and try implementing it! \n",
    "https://medium.com/@janplus/stratified-bayesian-blocks-2bd77c1e6cc7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can either apply this to your favorite data set, or you can use it on the stellar parameters table associated with the data set we pulled from MAST earlier (recall that you previously worked with the exoplanet parameters table). You can check out the fields you can search on using MAST CasJobs, or just download a FITS file of the full table, here: https://archive.stsci.edu/prepds/kg-radii/\n",
    "![](https://media.giphy.com/media/l0HlGEX1ZORa0aIvu/giphy.gif)\n",
    "<sub>This GIF is of Dan Shiffman, who has a Youtube channel called Coding Train</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "your_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete\n",
    "def stratified_bayesian_blocks("
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
