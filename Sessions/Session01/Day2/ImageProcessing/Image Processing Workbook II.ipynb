{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to read some data, take a look at it, smooth it, and think about\n",
    "whether the objects you've found are real.\n",
    "\n",
    "I've provided three python files:\n",
    "-     detection.py  Some code to detect objects\n",
    "-     imageProc.py\tSome image processing code to get you started\n",
    "-     utils.py\t\tConvenience functions for a Data object, I/O, and image display\n",
    "\n",
    "There are also some data files.  These started out as fits (as read with pyfits.py, not provided) but\n",
    "I saved them as numpy \".npy\" files (to be read with numpy.load)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import detection\n",
    "import imageProc\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some data.  \n",
    "\n",
    "Rather than asking you to install a display tool such as ds9, ginga, firefly, or aladin I've provided you with a lightweight image display tool, utils.mtv()\n",
    "\n",
    "The coloured overlay shows the mask bits that tells you which pixels are bad (its visibility is controlled\n",
    "by the alpha parameter).  The stretch is controlled by \"b\" (it's roughly the transition from a linear to a\n",
    "logarithmic stretch).\n",
    "\n",
    "You can print the value of pixel (x, y) with\n",
    "    print da.image[y, x]\n",
    "(note the order of the indices).  Here x and y can be scalars or numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "da = utils.Data()\n",
    "da.read()\n",
    "\n",
    "utils.mtv(da, b=10, alpha=0.8)\n",
    "xlim, ylim = (80, 400), (100, 400)\n",
    "\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the same data without marking the bad pixels -- you'll see that I fixed them. Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.mtv(da, b=10, alpha=0.0, fig=2)\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at the raw data, you can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = utils.Data()\n",
    "raw.read(readRaw=True)\n",
    "\n",
    "utils.mtv(raw, b=10, alpha=0.3)\n",
    "plt.xlim(740, 810); plt.ylim(230, 290)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next write a function to smooth the data with a Gaussian filter.  You can do the work with ```convolveWithGaussian``` in the next cell.\n",
    "\n",
    "_N.b._ You can make a copy of a ```Data``` object using ```da.copy()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian2D(beta):\n",
    "    size = int(3*abs(beta) + 1)\n",
    "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
    "    phi = np.exp(-(x**2 + y**2)/(2*beta**2))\n",
    "    phi /= phi.sum()\n",
    "\n",
    "    return phi\n",
    "\n",
    "def convolveWithGaussian(image, beta):\n",
    "    phi = gaussian2D(beta)\n",
    "\n",
    "    return scipy.signal.convolve(image, phi, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "\n",
    "sda = da.copy()\n",
    "beta = 2.5\n",
    "sda.image = convolveWithGaussian(sda.image, beta)\n",
    "\n",
    "utils.mtv(sda.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the filter's _effective area_ (and confirm or deny that I did my Gaussian integrals correctly in the lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phi = gaussian2D(beta)\n",
    "n_eff = 1/np.sum(phi**2)\n",
    "print \"n_eff = %.3f (analytically: %.3f)\" % (n_eff, 4*pi*beta**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That convolution seemed slow to me.  Go back to the cell, uncomment the ```%%timeit``` line, and run it again.  How long did it take?\n",
    "\n",
    "OK, take a look at the next cell and see if you can see what I did -- it's more python (and loops too) so it must be slower.  Is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convolveWithGaussian(image, beta):\n",
    "    def gaussian1D(beta):\n",
    "        size = int(3*abs(beta) + 1)\n",
    "        x = np.arange(-size, size+1)\n",
    "        phi = np.exp(-x**2/(2*beta**2))\n",
    "        phi /= phi.sum()\n",
    "\n",
    "        return phi\n",
    "\n",
    "    beta = 2.5\n",
    "    phi = gaussian1D(beta)\n",
    "\n",
    "    for y in range(0, image.shape[0]):\n",
    "        image[y] = scipy.signal.convolve(image[y], phi, mode='same')\n",
    "    for x in range(0, image.shape[1]):\n",
    "        image[:, x] = scipy.signal.convolve(image[:, x], phi, mode='same')\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look for objects.  We know how to do this;  we smooth the image with the PSF then look for peaks.  It's not totally trivial to find all the sets of connected pixels, so I provided you with a function ```detection.findObjects``` to do the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsigma = 3.5\n",
    "threshold = nsigma*sqrt(np.median(sda.variance)/n_eff)\n",
    "footprints = detection.findObjects(sda.image, threshold, grow=3)\n",
    "\n",
    "print \"I found %d objects\" % (len(footprints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at all our objects by looping over the footprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nShow = 10\n",
    "for foot in footprints.values()[0:nShow]:\n",
    "    print \"(%5d, %5d) %3d\" % (foot.centroid[0], foot.centroid[1], foot.npix)\n",
    "if len(footprints) > nShow:\n",
    "    print \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by setting a mask plane -- this way we'll be able to see all the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sda.clearMaskPlane(\"DETECTED\")\n",
    "detection.setMaskFromFootprints(sda, footprints, \"DETECTED\")\n",
    "\n",
    "utils.mtv(sda)\n",
    "\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing for the original (unsmoothed) image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "da.clearMaskPlane(\"DETECTED\")\n",
    "detection.setMaskFromFootprints(da, footprints, \"DETECTED\")\n",
    "\n",
    "utils.mtv(da, alpha=0.3)\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I lied to you; or at least I didn't tell you everything.  That 'data' was actually the output from the LSST simulator, which means that I know the Truth;  more accurately, I know the location of every photon that arrived from the sources without any sky background. The pixels are 0.2 arcseconds on a side.\n",
    "\n",
    "Let's overlay the detection mask on the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = utils.Data(image=da.truth, mask=sda.mask)\n",
    "utils.mtv(t, I0=1, b=0.01, alpha=0.6)\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you look at the direct image you can see things that seem real when you compare with the truth, for example the object at (156, 205).  So should we be using a lower threshold?  What happens if you choose a smaller value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so that picked up the object I pointed out, but it picked up some noise too.  How many false objects would I expect to detect per square degree?  Na√Øvely we'd expect each PSF-sized patch to be independent, so we can try using the tails of a Gaussian to estimate how many objects we'd detect per square degree.  If I take the area of a PSF to be 0.5 arcsec^2, I have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "\n",
    "pixelSize = 0.200\n",
    "\n",
    "nPerPsf = 0.5*scipy.special.erfc(nsigma/sqrt(2))\n",
    "nPerDeg = nPerPsf*3600**2/0.5\n",
    "\n",
    "print \"False positives per degree: %d  In data: %d\" % (\n",
    "    nPerDeg, nPerDeg/(3600/(da.image.shape[0]*pixelSize))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nick Kaiser has done the theory more carefully (it was easy for him;  he used results from a classic paper, Bardeen et. al, of which he was a co-author). The answer is that the number of peaks per-arcsecond is\n",
    "$$\n",
    "\\frac{1}{2^{5/2} \\pi^{3/2} \\beta^2} n_\\sigma e^{-n_\\sigma^2/2}\n",
    "$$\n",
    "\n",
    "I'm not as clever as Nick, but I do have access to a computer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "\n",
    "detection = reload(detection)\n",
    "\n",
    "ndeg = 1.0/2.0                       # Size of image we'll simulate (in degrees)\n",
    "size = int(3600*ndeg/pixelSize)      # Size of image we'll simulate (in pixels)\n",
    "im = np.zeros((size, size))\n",
    "\n",
    "nsigma, Poisson= 5, False\n",
    "np.random.seed(667)\n",
    "sigma = 10\n",
    "if Poisson:\n",
    "    mu = sigma**2\n",
    "    im += np.random.poisson(lam=mu, size=size*size).reshape(size, size) - mu\n",
    "else:\n",
    "    im += np.random.normal(scale=sigma, size=size*size).reshape(size, size)\n",
    "\n",
    "sim = convolveWithGaussian(im, beta)\n",
    "n_eff = 4*pi*beta**2   # Effective area of PSF\n",
    "\n",
    "threshold = nsigma*sigma/sqrt(n_eff)\n",
    "footprints = detection.findObjects(sim, threshold, grow=0)\n",
    "print \"%s %g %d %.1f\" % ((\"Poisson\" if Poisson else \"Gaussian\"), nsigma, \\\n",
    "                      len(footprints)/ndeg**2, \\\n",
    "                      3600**2*1/(2**2.5*pi**1.5*(beta*pixelSize)**2)*nsigma*exp(-nsigma**2/2))\n",
    "\n",
    "if not False:    \n",
    "    tmp = utils.Data(sim)\n",
    "    tmp.clearMaskPlane(\"DETECTED\")\n",
    "    detection.setMaskFromFootprints(tmp, footprints, \"DETECTED\")\n",
    "\n",
    "    utils.mtv(tmp, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By patiently running the previous cell several times, I arrived at:\n",
    "\n",
    "    nsigma Gaussian Poisson Gaussian Prediction\n",
    "    3      52288    55008   54848.1\n",
    "    3.5    11888    13296   12600\n",
    "    5      0        48      18.6\n",
    "    5.5    2        16      2.4\n",
    "    6      0        0       0.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
