{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e40f248",
   "metadata": {},
   "source": [
    "# Experimental design\n",
    "\n",
    "_Alex I. Malz (LINCC@CMU)_\n",
    "\n",
    "_LSSTC DSFP #16_\n",
    "\n",
    "I initially started a version of this problem set based on a data challenge I prepared for [Quarks to Cosmos with AI](https://events.mcs.cmu.edu/qtc2021/), which provides all the pieces you need to run an interesting experiment with photo-$z$ posterior PDF estimation models by a variety of metrics.\n",
    "However, that seems overly specific for the DSFP -- the goal is for you to learn to think adversarially in your own research, not in mine! -- so this one is more generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca8b94",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this problem set is for you to learn to identify and circumvent flaws in an experiment.\n",
    "To us as astronomers, an experiment may constitute the way we compare analysis methods or models or the impact of systematic imperfections in data or priors.\n",
    "The way we decide whether a procedure we came up with is sufficient for a task or better than some alternative is conditioned on our choice of metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828185a",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Here are four sets of two-dimensional data.\n",
    "You can imagine that they're the predictions of four models for estimating the relationship between variables $x$ and $y$ if you like (e.g. galaxy cluster concentration as a function of dark matter halo mass), or four observations that may or may not have come from a common process (e.g. folded time-series of variable stars).\n",
    "In this problem, you don't know the true values and can't conduct a controlled experiment, so we'll try to compare them using summary statistics we might actually apply to comparing the results of several estimation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\n",
    "y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n",
    "\n",
    "x2 = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\n",
    "y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\n",
    "\n",
    "x3 = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\n",
    "y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\n",
    "\n",
    "x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\n",
    "y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c79272",
   "metadata": {},
   "source": [
    "### 1a\n",
    "\n",
    "The simplest summary statistic is the first moment, a.k.a. the mean, $\\mu_{z} = \\frac{1}{N}\\sum_{i=1}^{N}z_{n}$.\n",
    "Write a function to compute the mean of a one-dimensional list.\n",
    "_Hint: Use `scipy.stats.moment()` if you want a shortcut._\n",
    "Compute the mean of $x$ and the mean of $y$ for each data set.\n",
    "Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e6ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "618bdaba",
   "metadata": {},
   "source": [
    "### 1b\n",
    "\n",
    "The next simplest summary statistic is the second moment, a.k.a. the variance, $\\sigma_{z}^{2} = \\frac{1}{N-1}\\sum_{i=1}^{N}(z_{n} - \\mu_{z})^{2}$.\n",
    "Write a function to compute the variance of a one-dimensional list.\n",
    "_Hint: Use `scipy.stats.moment()` if you want a shortcut._\n",
    "Compute the variance of $x$ and the variance of $y$ for each data set.\n",
    "Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db8e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67f16863",
   "metadata": {},
   "source": [
    "### 1c\n",
    "\n",
    "Judging by the first two moments, we need something a little more sophisticated to quantitatively distinguish these data sets.\n",
    "Let's make use of both $x$ and $y$ together.\n",
    "Pearson's correlation coefficient $r = \\frac{\\sum_{i=1}^{N}(x_{i}-\\mu_{x})(y_{i}-\\mu_{y})}{\\sqrt{\\sum_{i=1}^{N}(x_{i}-\\mu_{x})^{2}\\sum_{i=1}^{N}(y_{i}-\\mu_{y})^{2}}}$ is a measure of the degree to which variables $x$ and $y$ are correlated with one another.\n",
    "Write a function to compute the correlation coefficient of a two-dimensional data set.\n",
    "_Hint: Use `scipy.stats.pearsonr()` if you want a shortcut._\n",
    "Compute the $r$ for each data set.\n",
    "Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7b78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46ac13aa",
   "metadata": {},
   "source": [
    "### 1d\n",
    "\n",
    "They sure do seem to all be the same, yet the numbers in the lists are different!\n",
    "Let's try fitting a simple model to them.\n",
    "Recycle your code from earlier in the week to fit a line to data and apply it to these four data sets.\n",
    "_If you didn't get that far in a notebook, you can use `scipy.stats.linregress`._\n",
    "Interpret the resulting slope and intercept values _(and coefficient of determination, p-value, and standard error, if you used the canned fitting function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df1d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c53039",
   "metadata": {},
   "source": [
    "### 1e\n",
    "\n",
    "Finally, plot the four data sets, along with the line.\n",
    "Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20a34b8d",
   "metadata": {},
   "source": [
    "### 1f\n",
    "\n",
    "If you had to distinguish these data sets quantitatively, what metric(s) would you use?\n",
    "Implement at least one and show that the data sets don't have the same value(s) by your metric(s).\n",
    "Or, show that other metrics you can think of also can't distinguish them.\n",
    "\n",
    "_Hint: Start by thinking of a way to distinguish just one from the others._\n",
    "_As a challenge problem, then come up with another set of $(x, y)$ that will be degenerate by another metric._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3c827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0179bcab",
   "metadata": {},
   "source": [
    "Highlight for spoiler and credit.\n",
    "\n",
    "<font color='white'>\n",
    "By the way, Problem 1 is known as Anscombe's quartet and was devised to show statisticians the value of visual inspection over total reliance on quantitative metrics.\n",
    "The solutions can be found in [this nifty blog post](https://datasciencesphere.com/visualization/visualizing-anscombe-quartet-using-python/).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9089752",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Let's try a more complicated version of this.\n",
    "Download some other data sets [here](https://www.autodesk.com/content/dam/autodesk/www/autodesk-reasearch/Publications/pdf/SameStatsCode.zip).\n",
    "Let's inspect them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('generated_datasets/DatasaurusDozen.tsv', sep='\\t')\n",
    "print(data.columns)\n",
    "\n",
    "print(len(data['dataset'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfc461",
   "metadata": {},
   "source": [
    "### 2a\n",
    "\n",
    "We can separate them out and calculate some summary statistics:\n",
    "- How many points are in each?\n",
    "- What is the mean?\n",
    "- Variance?\n",
    "- Standard deviation?\n",
    "- Correlation coefficient?\n",
    "- Covariance $\\sum_{i=1}^{N}(x_{i}-\\mu_{x})(y_{i}-\\mu_{y})$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa71ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_grouped = data.groupby('dataset')\n",
    "print(datasets_grouped.agg(['count', 'mean', 'var', 'std']))\n",
    "print(data.groupby('dataset')[['x','y']].corr().iloc[0::2,-1])\n",
    "print(data.groupby('dataset').cov())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c7ba5",
   "metadata": {},
   "source": [
    "### 2b\n",
    "\n",
    "Let's try fitting a line again to check the slopes and intercepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cbc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de98bac",
   "metadata": {},
   "source": [
    "### 2c\n",
    "\n",
    "Now try plotting them, including the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c488b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae6bc38",
   "metadata": {},
   "source": [
    "### 2d\n",
    "\n",
    "Again, implement a metric that can distinguish between them, and then try to think of another data set that will be indistinguishable from one of the data sets by that metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa6f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3945bd22",
   "metadata": {},
   "source": [
    "Highlight for spoiler and credit.\n",
    "\n",
    "<font color='white'>\n",
    "Problem 2 uses the Datasaurus Dozen, a modern reenvisioning of Anscombe's quartet.\n",
    "The solutions can be found in [yet another nifty blog post](https://datasciencesphere.com/visualization/datasaurus-dozen-visualization-using-python/).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490cd77e",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Now that you've seen how metrics can be fooled by pathological data, I want you to apply this kind of critical thinking to your research!\n",
    "Talk with your neighbors to take apart a problem you (or they) are working on that involves comparing methods, models, or data.\n",
    "\n",
    "### 3a\n",
    "\n",
    "Articulate the metric(s) being used to make a decision.\n",
    "\n",
    "### 3b\n",
    "\n",
    "Think of a pathological control case that would lead to a counterintuitive conclusion using the given metric(s).\n",
    "\n",
    "### 3c\n",
    "\n",
    "Think about additional metrics that could protect your decision from being \"fooled\" by a test case that doesn't address the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a1281",
   "metadata": {},
   "source": [
    "## Problem $\\pi$\n",
    "\n",
    "If you don't want to do the open-ended thought experiment about a research problem you or another student is working on, check out the other notebook for this problem session to explore a specific one (surprise, it's photo-$z$s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b8afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSFP (Python 3)",
   "language": "python",
   "name": "dsfp_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
