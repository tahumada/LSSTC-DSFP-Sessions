{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1504a5b5",
   "metadata": {},
   "source": [
    "## Introduction to Bayesian Statistics\n",
    "LSSTC Data Science Fellowship Program Session 16\n",
    "\n",
    "**Jiayin Dong**, Flatiron Research Fellow\n",
    "\n",
    "CCA, Flatiron Institute\n",
    "\n",
    "September 2022\n",
    "\n",
    "---\n",
    "\n",
    "In the lecture, we learned Bayesian inference from three examples: (1) Draw balls out of a bag, (2) Observations with Gaussian noise, and (3) Fit a straight line to data. You may find the lecture material in this folder (https://github.com/jiayindong/LSSTC-DSFP-Sessions/tree/main/Sessions/Session16/Day1).\n",
    "\n",
    "The principle of the Bayesian inference is to update our inference on some parameters of interest $\\theta$ out of data $D$ from some prior knowledge on $\\theta$.\n",
    "\n",
    "Bayes' Theorem \n",
    "\n",
    "$p(\\theta|D) = \\cfrac{p(D|\\theta)p(\\theta)}{p(D)}$,\n",
    "\n",
    "where $p(\\theta|D)$ is the posterior, $p(D|\\theta)$ is the likelihood, and $p(\\theta)$ is the prior. $p(D)$ is the probablity of observing $D$, i.e., $p(D) = \\int{p(D|\\theta)p(\\theta)d\\theta}$.\n",
    "\n",
    "The approach we used to compute the posterior $p(\\theta|D)$ in the lecture is called *grid approximation*.\n",
    "\n",
    "Grid approximation in five steps,\n",
    "1. Build a grid for parameters of interest $\\theta$. The dimension of the grid depends on the number of parameters.\n",
    "2. At each parameter value on the grid, calculate the prior $p(\\theta_{\\rm grid})$.\n",
    "3. At each parameter value on the grid, calculate the likelihood $p(D|\\theta_{\\rm grid})$.\n",
    "4. At each parameter value on the grid, multiply the likelihood by the prior, $p(D|\\theta_{\\rm grid})p(\\theta_{\\rm grid})$. Note, this is the unnormalized posterior.\n",
    "5. Lastly, normalize the posterior by the sum of all values on the grid $\\Sigma_{\\theta_{\\rm grid}} p(D|\\theta_{\\rm grid})p(\\theta_{\\rm grid})$.\n",
    "\n",
    "This problem set is to apply the grid approximation to the three problems we discussed in the lecture.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font', **{'family':'sans-serif'})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ecb65",
   "metadata": {},
   "source": [
    "### Problem 1: Draw balls out of a bag\n",
    "\n",
    "We have a bag containing 4 balls. Each ball has two possible colors: black and white. We begin with no information on the number of black and white balls in the bag and want to update our guess on the number of black balls from observations (i.e., drawing balls out of the bag)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155197f",
   "metadata": {},
   "source": [
    "####  Problem 1(a) Make one draw\n",
    "\n",
    "We drew one ball out of the bag. And it is black.\n",
    "\n",
    "Step 1: Build a grid for $\\theta$. Let $\\theta$ here be the configurations of black and white balls.\n",
    "\n",
    "$\\theta$ has five possible states: 0, 1, 2, 3, 4 black balls out of 4 balls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = np.arange(5)\n",
    "θ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1999eca",
   "metadata": {},
   "source": [
    "Step 2: At each state of $\\theta$, calculate the prior.\n",
    "\n",
    "Since we have no previous information about the configuration, we use an uninformation prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a356c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.ones(5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the prior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, prior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(\\theta)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef24bf",
   "metadata": {},
   "source": [
    "Step 3: At each state of $\\theta$, calculate the likelihood.\n",
    "\n",
    "At $\\theta_0$, which has no black balls, $p( \\textrm{\"draw a black ball\"}|\\theta_0) = 0$\n",
    "\n",
    "At $\\theta_1$, which has one black ball and three white balls, $p( \\textrm{\"draw a black ball\"}|\\theta_1) = 1/4$\n",
    "\n",
    "...\n",
    "\n",
    "At $\\theta_4$, which has no white balls, $p( \\textrm{\"draw a black ball\"}|\\theta_4) = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783312d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = np.array([0, 1/4, 2/4, 3/4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43000bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the likelihood distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, likelihood, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(D|\\theta)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428cce24",
   "metadata": {},
   "source": [
    "Step 4: At each state of $\\theta$, calculate the unnormalized posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_posterior = prior*likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the unnormalized posterior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, unnormalized_posterior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'unnormalized $p(\\theta|D)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff942e42",
   "metadata": {},
   "source": [
    "Step 5: At each state of $\\theta$, normalize the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35146f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = unnormalized_posterior/np.sum(unnormalized_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the posterior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, posterior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(\\theta|D)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6547778",
   "metadata": {},
   "source": [
    "That's it. We solved the posterior of $\\theta$, i.e., an updated guess on the number of black balls after drawing a black ball out of the bag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b18b3",
   "metadata": {},
   "source": [
    "####  Problem 1(b) Make another draw\n",
    "\n",
    "After drawing the black ball, we put it back into the bag. We make another draw to improve our guess on the number of black balls in the bag. And we drew a white ball this time.\n",
    "\n",
    "Step 1: Build the grid. The grid of $\\theta$ remains the same.\n",
    "\n",
    "Step 2: Calculate the prior. Now we **do** have prior knowledge. Our prior knowledge is from the previous draw. I.e., the posterior we calculated from the previous draw becomes our prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.array([0,0.1,0.2,0.3,0.4]) # Note: This distribution is the same as the posterior in last cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1854675",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the prior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, prior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(\\theta)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f5655",
   "metadata": {},
   "source": [
    "Step 3: Calculate the likelihood. \n",
    "\n",
    "At $\\theta_0$, which has no black balls, $p( \\textrm{\"draw a white ball\"}|\\theta_0) = 1$\n",
    "\n",
    "At $\\theta_1$, which has one black ball and three white balls, $p( \\textrm{\"draw a white ball\"}|\\theta_1) = 3/4$\n",
    "\n",
    "...\n",
    "\n",
    "At $\\theta_4$, which has no white balls, $p( \\textrm{\"draw a white ball\"}|\\theta_4) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f358c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = # YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58870c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the likelihood distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, likelihood, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(D|\\theta)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16eb7dc",
   "metadata": {},
   "source": [
    "Step 4: At each state of $\\theta$, calculate the unnormalized posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_posterior = # YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the unnormalized posterior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, unnormalized_posterior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'unnormalized $p(\\theta|D)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545414a",
   "metadata": {},
   "source": [
    "Step 5: At each state of $\\theta$, normalize the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e508646",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = # YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the posterior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.scatter(θ, posterior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(\\theta|D)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b14ad",
   "metadata": {},
   "source": [
    "Again, we get our posterior. Since one draw is black and one draw is white, we get zero probability for $\\theta_0$ (no black balls) and $\\theta_4$ (all black balls). Our observation prefers an equal number of black and white balls, and that's why the posterior is picked at $\\theta_2$ and symmetric around $\\theta_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf805a",
   "metadata": {},
   "source": [
    "#### Problem 1(c) Add more balls.\n",
    "\n",
    "Let's say, instead of a bag of four balls, we now have a bag of 100 balls.\n",
    "\n",
    "We made 10 draws and got 6 black balls and 4 white balls.\n",
    "\n",
    "We begin with an uninformative prior. What the posterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1759264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define the theta\n",
    "# YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: write the prior\n",
    "# YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: write the likelihood\n",
    "# YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d59772",
   "metadata": {},
   "source": [
    "**Trick** We may instead write our likelihood as a binomial distribution.\n",
    "\n",
    "Call the SciPy binomial function [stats.binom.pmf(k, n, p)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom) where k = 6, n = 10, and p = $\\theta$/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_binomial = stats.binom.pmf(6, 10, θ/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d66465",
   "metadata": {},
   "source": [
    "Do two likelihood distributions look the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd944e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare likelihoood and likelihood_binomial\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.plot(θ, likelihood/np.sum(likelihood),label='Our likelihood')\n",
    "plt.plot(θ, likelihood_binomial/np.sum(likelihood_binomial), c='k', linestyle='--',label='Binomial')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(D|\\theta)$')\n",
    "plt.legend(framealpha=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 & 5: calcualte and normalize the posterior \n",
    "# YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the posterior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.plot(θ, posterior, c='k')\n",
    "plt.xlabel('Configurations (num of blacks balls)')\n",
    "plt.ylabel(r'$p(\\theta|D)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c3757",
   "metadata": {},
   "source": [
    "### Problem 2: Observations with Gaussian noise\n",
    "\n",
    "Astronomical observations come with noise. Instead of the *true* value (or mean value) of a parameter of interest is observed, we observe the true value plus some Gaussian noise $\\sigma$.\n",
    "\n",
    "We make observations of a parameter of interest $x$ with some known Gaussian noise $\\sigma$. We want to infer $x$ from observations on x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0454",
   "metadata": {},
   "source": [
    "#### Problem 2(a) Make one observation.\n",
    "\n",
    "Let's first generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e331cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "xtrue = 1.  # the \"true\" value of x\n",
    "σ = 1.  # the uncertainty sigma\n",
    "\n",
    "xobs = xtrue + np.random.normal(loc=0, scale=σ) # the observed x\n",
    "\n",
    "print(xobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bb1b1",
   "metadata": {},
   "source": [
    "Now we apply the grid approximation method to approximate the posterior of x given the observation, $p(x_{\\rm true}|x_{\\rm obs})$.\n",
    "\n",
    "Just a reminder of the grid approximation.\n",
    "1. Build a grid for parameters of interest $\\theta$. The dimension of the grid depends on the number of parameters.\n",
    "2. At each parameter value on the grid, calculate the prior $p(\\theta_{\\rm grid})$.\n",
    "3. At each parameter value on the grid, calculate the likelihood $p(D|\\theta_{\\rm grid})$.\n",
    "4. At each parameter value on the grid, multiply the likelihood by the prior, $p(D|\\theta_{\\rm grid})p(\\theta_{\\rm grid})$. Note, this is the unnormalized posterior.\n",
    "5. Lastly, normalize the posterior by the sum of all values on the grid $\\Sigma_{\\theta_{\\rm grid}} p(D|\\theta_{\\rm grid})p(\\theta_{\\rm grid})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b31a156",
   "metadata": {},
   "source": [
    "Step 1: Build a grid for xtrue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f84738",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let xgrid to be evenly spaced from -3 to 3 with 100 samples.\n",
    "xgrid = np.linspace(-3,3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77c0de",
   "metadata": {},
   "source": [
    "Step 2: At each value on $x_{\\rm grid}$, calculate the prior $p(x_{\\rm grid})$.\n",
    "\n",
    "Let's assume on uniform prior on x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.ones_like(xgrid)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the prior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.plot(xgrid, prior, c='k')\n",
    "plt.xlabel(r'x')\n",
    "plt.ylabel(r'$p(x)$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee2f28a",
   "metadata": {},
   "source": [
    "Step 3: At each value on xgrid, calculate the likelihood $p(x_{\\rm obs}|x_{\\rm grid})$.\n",
    "\n",
    "For a certain value of $x_{\\rm grid,i}$, the likelihood $p(x_{\\rm obs}|x_{\\rm grid,i})$ is the probablity of observing $x_{\\rm obs}$ from a Normal distribution with $\\mu = x_{\\rm grid,i}$ and $\\sigma$.\n",
    "\n",
    "We use the SciPy function [stats.norm.pdf(x, loc, scale)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html?highlight=norm#scipy.stats.norm) to calculate the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = stats.norm.pdf(xobs, xgrid, σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the likelihood distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.plot(xgrid, likelihood, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'$p(x_{\\textrm{obs}}|x_{\\textrm{true}})$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078e134",
   "metadata": {},
   "source": [
    "Steps 4 & 5: At each value on xgrid, calculate the posterior. And lastly, normalize the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbeb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = prior*likelihood\n",
    "posterior /= np.sum(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b9541",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot the posterior distribution\n",
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.plot(xgrid, posterior, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'$p(x_{\\textrm{true}}|x_{\\textrm{obs}})$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d6f73",
   "metadata": {},
   "source": [
    "The posterior has the shape like the likelihood because we used a uniform prior. \n",
    "\n",
    "Note that you may find stats.norm.pdf(xgrid, xobs, $\\sigma$) and stats.norm.pdf(xobs, xgrid, $\\sigma$) have the same mathematical expression. They have different statistical meanings. \n",
    "- stats.norm.pdf(xobs, xgrid, $\\sigma$) calculates the probability at xobs from Normal distributions N(xgrid, $\\sigma$).\n",
    "\n",
    "- stats.norm.pdf(xgrid, xobs, $\\sigma$) calculates the probabilities at xgrid from a Normal distribution N(xobs, $\\sigma$). \n",
    "\n",
    "#### Problem 2(b) Informative prior.\n",
    "\n",
    "Assume that we have some prior knowledge of x. Assume our prior is distribution as Normal(0.8, 0.5), i.e., $p(x) \\sim \\mathcal{N}(0.8, 0.5)$. \n",
    "\n",
    "Redo the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf4181",
   "metadata": {},
   "source": [
    "Let's ponder that for a moment. How did the posterior change and why it changed?\n",
    "\n",
    "#### Problem 2(c):  Many observations.\n",
    "\n",
    "Let's keep the assumption the same but now make 10 observations on x.\n",
    "\n",
    "Generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed689c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xobs = xtrue + np.random.normal(0,σ,size=10)\n",
    "print(xobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8015c4",
   "metadata": {},
   "source": [
    "Step 1: The xgrid remains the same.\n",
    "\n",
    "Step 2: Prior. Let's keep using the normal prior from the previous question.\n",
    "\n",
    "Step 3: Likelihood. Since now we have 10 observations, we need to calculate the likelihood for each observation and multiply them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cdd435",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "likelihood = np.ones_like(xgrid)\n",
    "\n",
    "for i, xobs_i in enumerate(xobs):\n",
    "    likelihood *= # YOUR_CODE_HERE\n",
    "    \n",
    "print(likelihood[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e58592",
   "metadata": {},
   "source": [
    "You may find the likelihood values are getting much smaller when we have more observations. It will be troublesome as they reach the smallest representable number in double (or single) precision.\n",
    "\n",
    "Instead, we could use log_likelihood, which is the natural log (ln) of the likelihood.\n",
    "\n",
    "Redo the likelihood calculation above with log_likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b5049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_likelihood = np.zeros_like(xgrid)\n",
    "\n",
    "for i, xobs_i in enumerate(xobs):\n",
    "    log_likelihood += # YOUR_CODE_HERE\n",
    "    \n",
    "print(log_likelihood[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dada06f",
   "metadata": {},
   "source": [
    "Steps 4 & 5: Calculate the posterior and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d904b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_posterior = np.log(prior) + log_likelihood\n",
    "posterior = np.exp(log_posterior)\n",
    "posterior /= np.sum(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5,2.7),dpi=110)\n",
    "plt.plot(xgrid, posterior, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'$p(x_{\\textrm{true}}|x_{\\textrm{obs}})$')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934b07b",
   "metadata": {},
   "source": [
    "### Problem 3: Fit a straight line to data\n",
    "\n",
    "Lastly, let's apply the grid approximation method to model a straight line.\n",
    "\n",
    "We have two parameters of interest, the slope of the line $m$ and the intercept of the line $b$. The line model is described as $y = mx + b$.\n",
    "\n",
    "We made 10 observations of y but with some Gaussian noise $\\sigma$. Assume that we know the exact x values.\n",
    "\n",
    "Let's generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,10)\n",
    "\n",
    "m_true = 1.\n",
    "b_true = 0.5\n",
    "y_true = m_true*x + b_true\n",
    "\n",
    "σ = 0.2\n",
    "\n",
    "y_obs = y_true + np.random.normal(size=len(y_true))*σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2.7),dpi=110)\n",
    "plt.errorbar(x, y_obs, yerr=σ, linestyle='', fmt='o', c='k')\n",
    "plt.plot(x, y_true, c='grey', lw=1, zorder=0)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cffef",
   "metadata": {},
   "source": [
    "Let's do the grid approximation to infer the slope and the intercept ${m, b}$.\n",
    "\n",
    "1. Build a grid for parameters of interest $\\theta$. The dimension of the grid depends on the number of parameters.\n",
    "2. At each parameter value on the grid, calculate the prior $p(\\theta_{\\rm grid})$.\n",
    "3. At each parameter value on the grid, calculate the likelihood $p(D|\\theta_{\\rm grid})$.\n",
    "4. At each parameter value on the grid, multiply the likelihood by the prior, $p(D|\\theta_{\\rm grid})p(\\theta_{\\rm grid})$. Note, this is the unnormalized posterior.\n",
    "5. Lastly, normalize the posterior by the sum of all values on the grid $\\Sigma_{\\theta_{\\rm grid}} p(D|\\theta_{\\rm grid})p(\\theta_{\\rm grid})$.\n",
    "\n",
    "Step 1: Build the grid. We use [np.meshgrid](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) to broadcast the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfebdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgrid = np.linspace(0,2,200)\n",
    "bgrid = np.linspace(0,1,100)\n",
    "mv, bv = np.meshgrid(mgrid, bgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02960617",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,mv,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('Broadcast m grid along b direction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed0403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,bv,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('Broadcast b grid along m direction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964a114",
   "metadata": {},
   "source": [
    "Step 2: At each grid value $(m_i, b_j)$, calcuate the prior.\n",
    "\n",
    "Let's assume uniform priors on $m$ and $b$. Note that because of the geometry of the problem, a uniform prior on $m$ is biased towards high slopes.\n",
    "\n",
    "$ m \\sim {\\rm Uniform}(0, 2)$\n",
    "\n",
    "$ b \\sim {\\rm Uniform}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0685eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_m = # YOUR_CODE_HERE\n",
    "prior_b = # YOUR_CODE_HERE\n",
    "\n",
    "prior_mv, prior_bv = np.meshgrid(prior_m, prior_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90537852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,prior_mv,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('m prior (constant)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffa5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,prior_bv,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('b prior (constant)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829700b0",
   "metadata": {},
   "source": [
    "Our prior here should now be the product $p(m)p(b)$ or the sum $\\log(m)+\\log(b)$ if we take the natural log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc1df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior = np.log(prior_mv)+np.log(prior_bv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,prior_bv,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('log-prior (constant)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f891b0",
   "metadata": {},
   "source": [
    "Step 3: At each grid value $(m_i, b_j)$, calcuate the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c28193",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = 0.\n",
    "\n",
    "for i, this_y_obs in enumerate(y_obs):\n",
    "    \n",
    "    this_y_true = # YOUR_CODE_HERE\n",
    "    \n",
    "    log_likelihood += # YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0552a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,log_likelihood,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('log-likelihood')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80293a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,np.exp(log_likelihood),cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('likelihood')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112a73d",
   "metadata": {},
   "source": [
    "Step 4 & 5: At each grid value $(m_i, b_j)$, calcuate the posterior and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_posterior = # YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,log_posterior,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('posterior')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = np.exp(log_posterior)\n",
    "posterior /= np.sum(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c981496",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "plt.pcolormesh(mgrid,bgrid,posterior,cmap='plasma')\n",
    "plt.xlabel('m grid')\n",
    "plt.ylabel('b grid')\n",
    "plt.colorbar()\n",
    "plt.title('posterior')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b293ff",
   "metadata": {},
   "source": [
    "**Bonus Problem** Try different priors on $m$ and $b$. How does the posterior change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf4a57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
