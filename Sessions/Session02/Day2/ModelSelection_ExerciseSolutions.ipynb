{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection For Machine Learning\n",
    "\n",
    "In this exercise, we will explore methods to do model selection in a machine learning context, in particular cross-validation and information criteria. At the same time, we'll learn about `scikit-learn`'s class structure and how to build a pipeline.\n",
    "\n",
    "## Why Model Selection?\n",
    "\n",
    "There are several reasons why you might want to perform model selection:\n",
    "\n",
    "* You might not be sure which machine learning algorithm is most appropriate.\n",
    "* The algorithm you have chosen might have a regularization parameter whose value you want to determine.\n",
    "* The algorithm you have chosen might have other parameters (e.g. the depth of a decision tree, the number of clusters in `KMeans`, ...) you would like to determine.\n",
    "* You might not be sure which of your features are the most useful/predictive.\n",
    "\n",
    "**Question**: Can you think of other reasons and contexts in which model selection might be important?\n",
    "\n",
    "Your decisions for how to do model selection depend very strongly (like everything else in machine learning) on the purpose of your machine learning procedure. Is your main purpose to accurately **predict** outcomes for new samples? Or are you trying to **infer** something about the system? \n",
    "\n",
    "Inference generally restricts the number of algorithms you can reasonably use, and also the number of model selection procedures you can apply. In the following, assume that everything below works for prediction problems; I will point out methods for inference where appropriate. Additionally, assume that everything below works for *supervised machine learning*. We will cover *unsupervised* methods further below.\n",
    "\n",
    "## Imports\n",
    "\n",
    "Let's first import some stuff we're going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# comment out this line if you don't have seaborn installed\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to need some data. We'll work with the star-galaxy data from the first session. This uses the `astroquery` package and then queries the top 10000 observations from SDSS (see [this exercise](https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/master/Session1/Day4/StarGalaxyRandomForest.ipynb) for more details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/astroquery/sdss/__init__.py:28: UserWarning: Experimental: SDSS has not yet been refactored to have its API match the rest of astroquery (but it's nearly there).\n",
      "  warnings.warn(\"Experimental: SDSS has not yet been refactored to have its API \"\n"
     ]
    }
   ],
   "source": [
    "# execute this line:\n",
    "from astroquery.sdss import SDSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;Table length=10000&gt;\n",
       "<table id=\"table4691112904\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>psfMag_r</th><th>fiberMag_r</th><th>fiber2Mag_r</th><th>petroMag_r</th><th>deVMag_r</th><th>expMag_r</th><th>modelMag_r</th><th>cModelMag_r</th><th>class</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>bytes6</th></tr></thead>\n",
       "<tr><td>18.50319</td><td>18.65275</td><td>19.33509</td><td>17.54539</td><td>17.31526</td><td>17.58132</td><td>17.58132</td><td>17.48715</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.02659</td><td>19.32441</td><td>19.80892</td><td>19.05827</td><td>19.03468</td><td>19.03111</td><td>19.03111</td><td>19.03111</td><td>STAR</td></tr>\n",
       "<tr><td>19.8809</td><td>19.77895</td><td>20.46623</td><td>19.3534</td><td>19.1864</td><td>19.35493</td><td>19.35493</td><td>19.24559</td><td>GALAXY</td></tr>\n",
       "<tr><td>22.03563</td><td>22.06141</td><td>22.68416</td><td>21.51795</td><td>21.03554</td><td>21.31751</td><td>21.31751</td><td>21.31751</td><td>GALAXY</td></tr>\n",
       "<tr><td>21.56726</td><td>21.57312</td><td>22.22178</td><td>20.4583</td><td>19.93309</td><td>20.39825</td><td>20.39819</td><td>20.20402</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.66813</td><td>18.75309</td><td>19.36792</td><td>17.83372</td><td>17.69468</td><td>17.89914</td><td>17.6947</td><td>17.75269</td><td>GALAXY</td></tr>\n",
       "<tr><td>20.19068</td><td>20.33947</td><td>20.93226</td><td>19.77666</td><td>19.63458</td><td>19.74873</td><td>19.74872</td><td>19.74873</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.41619</td><td>19.38348</td><td>20.15486</td><td>17.67687</td><td>17.16815</td><td>17.63962</td><td>17.63962</td><td>17.63962</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.88878</td><td>18.91179</td><td>19.57415</td><td>17.3317</td><td>17.02896</td><td>17.43539</td><td>17.02898</td><td>17.06256</td><td>GALAXY</td></tr>\n",
       "<tr><td>17.73892</td><td>17.8784</td><td>18.4601</td><td>16.81384</td><td>16.80538</td><td>17.07542</td><td>16.80538</td><td>16.80538</td><td>GALAXY</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>19.24749</td><td>19.50776</td><td>20.10474</td><td>18.66996</td><td>18.61142</td><td>18.78825</td><td>18.61142</td><td>18.61683</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.85847</td><td>19.0704</td><td>19.73915</td><td>17.85506</td><td>17.58484</td><td>17.82618</td><td>17.82618</td><td>17.73945</td><td>GALAXY</td></tr>\n",
       "<tr><td>17.88114</td><td>18.16021</td><td>18.73313</td><td>17.69177</td><td>17.64868</td><td>17.64409</td><td>17.64409</td><td>17.64409</td><td>STAR</td></tr>\n",
       "<tr><td>18.36227</td><td>18.63728</td><td>19.22842</td><td>17.76154</td><td>17.72115</td><td>17.91659</td><td>17.72115</td><td>17.72115</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.39928</td><td>19.56483</td><td>20.29491</td><td>17.66843</td><td>17.08915</td><td>17.55575</td><td>17.55575</td><td>17.55575</td><td>GALAXY</td></tr>\n",
       "<tr><td>18.05847</td><td>18.21004</td><td>18.89647</td><td>16.85453</td><td>16.62304</td><td>16.84302</td><td>16.84302</td><td>16.76329</td><td>GALAXY</td></tr>\n",
       "<tr><td>22.23627</td><td>22.52658</td><td>23.06609</td><td>21.30207</td><td>21.25972</td><td>21.42846</td><td>21.25974</td><td>21.26578</td><td>GALAXY</td></tr>\n",
       "<tr><td>19.66558</td><td>19.97335</td><td>20.53659</td><td>19.27357</td><td>19.22064</td><td>19.36352</td><td>19.22064</td><td>19.22064</td><td>GALAXY</td></tr>\n",
       "<tr><td>20.70572</td><td>21.10135</td><td>21.57685</td><td>20.69317</td><td>20.65731</td><td>20.66223</td><td>20.65733</td><td>20.65731</td><td>STAR</td></tr>\n",
       "<tr><td>21.83704</td><td>22.13966</td><td>22.7099</td><td>21.37834</td><td>21.28071</td><td>21.44025</td><td>21.44045</td><td>21.40327</td><td>GALAXY</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=10000>\n",
       "psfMag_r fiberMag_r fiber2Mag_r petroMag_r ... modelMag_r cModelMag_r class \n",
       "float64   float64     float64    float64   ...  float64     float64   bytes6\n",
       "-------- ---------- ----------- ---------- ... ---------- ----------- ------\n",
       "18.50319   18.65275    19.33509   17.54539 ...   17.58132    17.48715 GALAXY\n",
       "19.02659   19.32441    19.80892   19.05827 ...   19.03111    19.03111   STAR\n",
       " 19.8809   19.77895    20.46623    19.3534 ...   19.35493    19.24559 GALAXY\n",
       "22.03563   22.06141    22.68416   21.51795 ...   21.31751    21.31751 GALAXY\n",
       "21.56726   21.57312    22.22178    20.4583 ...   20.39819    20.20402 GALAXY\n",
       "18.66813   18.75309    19.36792   17.83372 ...    17.6947    17.75269 GALAXY\n",
       "20.19068   20.33947    20.93226   19.77666 ...   19.74872    19.74873 GALAXY\n",
       "19.41619   19.38348    20.15486   17.67687 ...   17.63962    17.63962 GALAXY\n",
       "18.88878   18.91179    19.57415    17.3317 ...   17.02898    17.06256 GALAXY\n",
       "17.73892    17.8784     18.4601   16.81384 ...   16.80538    16.80538 GALAXY\n",
       "     ...        ...         ...        ... ...        ...         ...    ...\n",
       "19.24749   19.50776    20.10474   18.66996 ...   18.61142    18.61683 GALAXY\n",
       "18.85847    19.0704    19.73915   17.85506 ...   17.82618    17.73945 GALAXY\n",
       "17.88114   18.16021    18.73313   17.69177 ...   17.64409    17.64409   STAR\n",
       "18.36227   18.63728    19.22842   17.76154 ...   17.72115    17.72115 GALAXY\n",
       "19.39928   19.56483    20.29491   17.66843 ...   17.55575    17.55575 GALAXY\n",
       "18.05847   18.21004    18.89647   16.85453 ...   16.84302    16.76329 GALAXY\n",
       "22.23627   22.52658    23.06609   21.30207 ...   21.25974    21.26578 GALAXY\n",
       "19.66558   19.97335    20.53659   19.27357 ...   19.22064    19.22064 GALAXY\n",
       "20.70572   21.10135    21.57685   20.69317 ...   20.65733    20.65731   STAR\n",
       "21.83704   22.13966     22.7099   21.37834 ...   21.44045    21.40327 GALAXY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSquery = \"\"\"SELECT TOP 10000 \n",
    "             p.psfMag_r, p.fiberMag_r, p.fiber2Mag_r, p.petroMag_r, \n",
    "             p.deVMag_r, p.expMag_r, p.modelMag_r, p.cModelMag_r, \n",
    "             s.class\n",
    "             FROM PhotoObjAll AS p JOIN specObjAll s ON s.bestobjid = p.objid\n",
    "             WHERE p.mode = 1 AND s.sciencePrimary = 1 AND p.clean = 1 AND s.class != 'QSO'\n",
    "             ORDER BY p.objid ASC\n",
    "               \"\"\"\n",
    "SDSSts = SDSS.query_sql(TSquery)\n",
    "SDSSts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Visualize this data set. What representation is most appropriate, do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Let's now do some machine learning. In this exercise, you are going to use a random forest classifier to classify this data set. Here are the steps you'll need to perform:\n",
    "* Split the column with the classes (stars and galaxies) from the rest of the data\n",
    "* Cast the features and the classes to numpy arrays\n",
    "* Split the data into a *test* set and a *training* set. The training set will be used to train the classifier; the test set we'll reserve for the very end to test the final performance of the model (more on this on Friday). You can use the `scikit-learn` function `test_train_split` for this task\n",
    "* Define a `RandomForest` object from the `sklearn.ensemble` module. Note that the `RandomForest` class has three parameters:\n",
    "    - `n_estimators`: The number of decision trees in the random forest\n",
    "    - `max_features`: The maximum number of features to use for the decision trees\n",
    "    - `min_samples_leaf`: The minimum number of samples that need to end up in a terminal leaf (this effectively limits the number of branchings each tree can make)\n",
    "* We'll want to use *cross-validation* to decide between parameters. You can do this with the `scikit-learn` class `GridSearchCV`. This class takes a classifier as an input, along with a dictionary of the parameter values to search over.\n",
    "\n",
    "In the earlier lecture, you learned about four different types of cross-validation:\n",
    "* hold-out cross validation, where you take a single validation set to compare your algorithm's performance to\n",
    "* k-fold cross validation, where you split your training set into k subsets, each of which holds out a different portion of the data\n",
    "* leave-one-out cross validation, where you have N different subsets, each of which leaves just one sample as a validation set\n",
    "* random subset cross validation, where you pick a random subset of your data points k times as your validation set.\n",
    "\n",
    "**Exercise 2a**: Which of the four algorithms is most appropriate here? And why?\n",
    "\n",
    "**Answer**: In this case, k-fold CV or random subset CV seem to be the most appropriate algorithms to use.\n",
    "* Using hold-out cross validation leads to a percentage of the data not being used for training at all. \n",
    "* Given that the data set is not too huge, using k-fold CV probably won't slow down the ML procedure too much.\n",
    "* LOO CV is particularly useful for small data sets, where even training on a subset of the training data is difficult (for example because there are only very few examples of a certain class). \n",
    "* Random subset CV could also yield good results, since there's no real ordering to the training data. Do not use this algorithm when the ordering matters (for example in Hidden Markov Models)\n",
    "\n",
    "**Important:** One important thing to remember that cross-validation crucially depends on your *samples* being **independent** from each other. Be sure that this is the case before using it. For example, say you want to classify images of galaxies, but your data set is small, and you're not sure whether your algorithm is rotation independent. So you might choose to use the same images multiple times in your training data set, but rotated by a random degree. In this case, you *have* to make sure all versions of the same image are included in the **same** data set (either the training, the validation or the test set), and not split across data sets! If you don't, your algorithm will be unreasonably confident in its accuracy (because you are training and validating essentially on the same data points). \n",
    "\n",
    "Note that `scikit-learn` can actually deal with that! The class [`GroupKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold) allows k-fold cross validation using an array of indices for your training data. Validation sets will only be split among samples with *different* indices. \n",
    "\n",
    "But this was just an aside. Last time, you used a random forest and used k-fold cross validation to effectively do model selection for the different parameters that the random forest classifier uses. \n",
    "\n",
    "**Exercise 2b**: Now follow the instructions above and implement your random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 100, 300], 'max_features': [1, 3, 7], 'min_samples_leaf': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set the random state\n",
    "rs = 23  # we are in Chicago after all\n",
    "\n",
    "# extract feature names, remove class\n",
    "feats = list(SDSSts.columns)\n",
    "feats.remove('class')\n",
    "\n",
    "# cast astropy table to pandas, remove classes\n",
    "X = np.array(SDSSts[feats].to_pandas())\n",
    "\n",
    "# our classes are the outcomes to classify on\n",
    "y = np.array(SDSSts['class'])\n",
    "\n",
    "# let's do a split in training and test set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = rs)\n",
    "# we'll leave the test set for later.\n",
    "\n",
    "# instantiate the random forest classifier:\n",
    "RFmod = RandomForestClassifier()\n",
    "\n",
    "# do a grid search over the free random forest parameters:\n",
    "pars = {\"n_estimators\": [10, 100, 300],\n",
    "        \"max_features\": [1, 3, 7], \n",
    "        \"min_samples_leaf\": [1,10]}\n",
    "\n",
    "grid_results = GridSearchCV(RandomForestClassifier(), \n",
    "                            pars,\n",
    "                            cv = 5)\n",
    "\n",
    "grid_results.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2c**: Take a look at the different validation scores for the different parameter combinations. Are they very different or are they similar? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.96371, std: 0.00219, params: {'max_features': 1, 'n_estimators': 10, 'min_samples_leaf': 1},\n",
       " mean: 0.96457, std: 0.00204, params: {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 1},\n",
       " mean: 0.96429, std: 0.00162, params: {'max_features': 1, 'n_estimators': 300, 'min_samples_leaf': 1},\n",
       " mean: 0.96657, std: 0.00138, params: {'max_features': 1, 'n_estimators': 10, 'min_samples_leaf': 10},\n",
       " mean: 0.96786, std: 0.00121, params: {'max_features': 1, 'n_estimators': 100, 'min_samples_leaf': 10},\n",
       " mean: 0.96700, std: 0.00172, params: {'max_features': 1, 'n_estimators': 300, 'min_samples_leaf': 10},\n",
       " mean: 0.95957, std: 0.00322, params: {'max_features': 2, 'n_estimators': 10, 'min_samples_leaf': 1},\n",
       " mean: 0.96186, std: 0.00273, params: {'max_features': 2, 'n_estimators': 100, 'min_samples_leaf': 1},\n",
       " mean: 0.96229, std: 0.00351, params: {'max_features': 2, 'n_estimators': 300, 'min_samples_leaf': 1},\n",
       " mean: 0.96757, std: 0.00259, params: {'max_features': 2, 'n_estimators': 10, 'min_samples_leaf': 10},\n",
       " mean: 0.96829, std: 0.00274, params: {'max_features': 2, 'n_estimators': 100, 'min_samples_leaf': 10},\n",
       " mean: 0.96829, std: 0.00278, params: {'max_features': 2, 'n_estimators': 300, 'min_samples_leaf': 10}]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the scores are very similar, and have very small variance between the different cross validation instances. It can be useful to do this kind of representation to see for example whether there is a large variance in the cross-validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validating Multiple Model Components\n",
    "\n",
    "In most machine learning applications, your machine learning algorithm might not be the only component having free parameters. You might not even be sure which machine learning algorithm to use! \n",
    "\n",
    "For demonstration purposes, imagine you have many features, but many of them might be correlated. A standard dimensionality reduction technique to use is [Principal Component Analysis](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). \n",
    "\n",
    "**Exercise 4**: The number of features in our present data set is pretty small, but let's nevertheless attempt to reduce dimensionality with PCA. Run a PCA decomposition in 2 dimensions and plot the results. Colour-code stars versus calaxies. How well do they separate along the principal components?\n",
    "\n",
    "*Hint*: Think about whether you can run PCA on training and test set separately, or whether you need to run it on both together *before* doing the train-test split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x119b85c50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHwCAYAAABkJOM0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11982b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# instantiate the PCA object\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit and transform the samples:\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# make a plot object\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,8))\n",
    "\n",
    "# loop over number of classes:\n",
    "for i,l in enumerate(np.unique(y)):\n",
    "    members = y == l\n",
    "    plt.scatter(X_pca[members, 0], X_pca[members, 1], \n",
    "                color=sns.color_palette(\"colorblind\",8)[i],\n",
    "                label=l)\n",
    "    \n",
    "ax.set_xlabel(\"PCA Component 1\")\n",
    "ax.set_ylabel(\"PCA Component 2\")\n",
    "    \n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Re-do the classification on the PCA components instead of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 100, 300], 'max_features': [1, 2], 'min_samples_leaf': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train PCA on training data set\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "\n",
    "# apply to test set\n",
    "X_pca_test = pca.transform(X_test)\n",
    "\n",
    "# we'll leave the test set for later.\n",
    "\n",
    "# instantiate the random forest classifier:\n",
    "RFmod = RandomForestClassifier()\n",
    "\n",
    "# do a grid search over the free random forest parameters:\n",
    "pars = {\"n_estimators\": [10, 100, 300],\n",
    "        \"max_features\": [1, 2], \n",
    "        \"min_samples_leaf\": [1,10]}\n",
    "\n",
    "grid_results = GridSearchCV(RandomForestClassifier(), \n",
    "                            pars,\n",
    "                            cv = 5)\n",
    "\n",
    "grid_results.fit(X_pca_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96828571428571431"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In general, you should (cross-)validate both your data transformations and your classifiers!\n",
    "\n",
    "But how do we know whether two components was really the right number to choose? perhaps it should have been three? Or four? Ideally, we would like to include the feature engineering in our cross validation procedure. In principle, you can do this by running a complicated for-loop. In practice, this is what `scikit-learn`s [Pipeline](http://scikit-learn.org/stable/modules/pipeline.html) is for! A `Pipeline` object takes a list of tuples of `(\"string\", ScikitLearnObject)` pairs as input and strings them together (your feature vector `X` will be put first through the first object, then the second object and so on sequentially).\n",
    "\n",
    "**Note**: `scikit-learn` distinguishes between *transformers* (i.e. classes that transform the features into something else, like PCA, t-SNE, StandardScaler, ...) and *predictors* (i.e. classes that produce predictions, such as random forests, logistic regression, ...). In a pipeline, all but the last objects must be transformers; the last object can be either.\n",
    "\n",
    "**Exercise 6**: Make a pipeline including (1) a PCA object and (2) a random forest classifier. Cross-validate both the PCA components and the parameters of the random forest classifier. What is the best number of PCA components to use?\n",
    "\n",
    "*Hint*: You can also use the convenience function [`make_pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline) to creatue your pipeline. \n",
    "\n",
    "*Hint*: Check the documentation for the precise notation to use for cross-validating parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('pca', PCA(copy=True, n_components=None, whiten=False)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [2, 4, 6, 8], 'clf__min_samples_leaf': [1, 10], 'clf__n_estimators': [10, 100, 300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# make a list of name-estimator tuples\n",
    "estimators = [('pca', PCA()), ('clf', RandomForestClassifier())]\n",
    "\n",
    "# instantiate the pipeline\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# make a dictionary of parameters\n",
    "params = dict(pca__n_components=[2, 4, 6, 8],\n",
    "              clf__n_estimators=[10, 100, 300],\n",
    "              clf__min_samples_leaf=[1,10])\n",
    "\n",
    "# perform the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970571428571\n",
      "{'pca__n_components': 6, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `n_components=6` works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Algorithms\n",
    "\n",
    "So far, we've just picked PCA because it's common. But what if there's a better algorithm for dimensionality reduction out there for our problem? Or what if you'd want to compare random forests to other classifiers? \n",
    "\n",
    "In this case, your best option is to split off a separate validation set, perform cross-validation for each algorithm separately, and then compare the results using hold-out cross validation and your validation set (**Note**: Do *not* use your test set for this! Your test set is *only* used for your final error estimate!)\n",
    "\n",
    "Doing CV across algorithms is difficult, since the `KFoldCV` object needs to know which parameters belong to which algorithms, which is difficult to do. \n",
    "\n",
    "**Exercise 7**: Pick an algorithm from the [manifold learning](http://scikit-learn.org/stable/modules/manifold.html#manifold) library in `scikit-learn`, cross-validate a random forest for both, and compare the performance of both.\n",
    "\n",
    "**Important**: Do *not* choose t-SNE. The reason is that t-SNE does not generalize to new samples! This means while it's useful for data visualization, you cannot train a t-SNE transformation (in the `scikit-learn` implementation) on one part of your data and apply it to another!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.971607142857\n",
      "Best parameter set: {'pca__n_components': 4, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "Validation score for model with PCA: 0.961428571429\n",
      "Best score: 0.971428571429\n",
      "Best parameter set: {'lle__n_components': 4, 'clf__min_samples_leaf': 10, 'clf__n_estimators': 10, 'lle__n_neighbors': 100}\n",
      "Validation score for model with PCA: 0.957142857143\n"
     ]
    }
   ],
   "source": [
    "# First, let's redo the train-test split to split the training data \n",
    "# into training and hold-out validation set\n",
    "X_train_new, X_val, y_train_new, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size = 0.2, \n",
    "                                                          random_state = rs)\n",
    "\n",
    "\n",
    "# Now we have to re-do the PCA pipeline:\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# make a list of name-estimator tuples\n",
    "estimators = [('pca', PCA()), ('clf', RandomForestClassifier())]\n",
    "\n",
    "# instantiate the pipeline\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "# make a dictionary of parameters\n",
    "params = dict(pca__n_components=[2, 4, 6, 8],\n",
    "              clf__n_estimators=[10, 100, 300],\n",
    "              clf__min_samples_leaf=[1,10])\n",
    "\n",
    "# perform the grid search\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "grid_search.fit(X_train_new, y_train_new)\n",
    "\n",
    "print(\"Best score: \" + str(grid_search.best_score_))\n",
    "print(\"Best parameter set: \" + str(grid_search.best_params_))\n",
    "print(\"Validation score for model with PCA: \" + str(grid_search.score(X_val, y_val)))\n",
    "\n",
    "# I'm going to pick locally linear embedding here:\n",
    "# LLE has two free parameters: \n",
    "# - the number of parameters to use `n_neighbors`\n",
    "# - the number of components in the output\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# make a list of name-estimator tuples\n",
    "estimators = [('lle', LocallyLinearEmbedding()), ('clf', RandomForestClassifier())]\n",
    "\n",
    "# instantiate the pipeline\n",
    "pipe2 = Pipeline(estimators)\n",
    "\n",
    "# make a dictionary of parameters\n",
    "params = dict(lle__n_components=[2, 4, 6, 8],\n",
    "              lle__n_neighbors=[5, 10, 100],\n",
    "              clf__n_estimators=[10, 100, 300],\n",
    "              clf__min_samples_leaf=[1,10])\n",
    "\n",
    "# perform the grid search\n",
    "grid_search2 = GridSearchCV(pipe2, param_grid=params)\n",
    "grid_search2.fit(X_train_new, y_train_new)\n",
    "\n",
    "print(\"Best score: \" + str(grid_search2.best_score_))\n",
    "print(\"Best parameter set: \" + str(grid_search2.best_params_))\n",
    "print(\"Validation score for model with LLE: \" + str(grid_search2.score(X_val, y_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like PCA does slightly better as a dimensionality reduction method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Interpreting Results\n",
    "\n",
    "Earlier today, we talked about interpreting machine learning models. Let's see how you would go about this in practice.\n",
    "\n",
    "* Repeat your classification with a logistic regression model.\n",
    "* Is the logistic regression model easier or harder to interpret? Why?\n",
    "* Assume you're interested in which features are the most relevant to your classification (because they might have some bearing on the underlying physics). Would you do your classification on the original features or the PCA transformation? Why?\n",
    "* Change the subset of parameters used in the logistic regression models. Look at the weights. Do they change? How? Does that affect your interpretability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=10, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegressionCV(penalty=\"l2\", Cs=10, cv=10)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.88906087,  1.95530763, -2.43079597,  0.57283392,  2.30630584,\n",
       "        -2.34414147,  1.95936236,  4.29013675]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1**: Whether the model is easier or harder to interpret depends on what type of interpretability is desired. If you are interested in how the **features** influence the classification, the logistic regression model is easier to interpret: because random forests is an ensemble method, it's very hard to understand in detail how a prediction comes about (since the individual decision trees may have very different structures). However, for very large feature spaces with complicated, engineered features, your linear model (the logistic regression model) loses interpretability in how the parameters affect the outcomes just as much.\n",
    "\n",
    "**Answer 2**: The more feature engineering you do, the harder it will be to interpret the results. The PCA features are a linear transformation of your original eight features. But what do they mean in physical terms? Who knows?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.85785953, -18.54078442,   0.43157384,   5.81193484,\n",
       "         -8.7399514 ,  -3.4353291 ,  10.01516215]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's leave out the first parameter and see whether the coefficients change:\n",
    "lr.fit(X_train[:,1:], y_train)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3**: Some of the coefficients just changed sign! This is one of the problems with directly interpreting linear models: they are quite sensitive to the structure of the feature space. If you took these parameters and interpreted them in a causal sense, you might get completely different causal inferences depending on which parameters you use so be careful to check how robust your model is to changes in the feature space!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even More Challenging Challenge Problem: Implementing Your Own Estimator\n",
    "\n",
    "Sometimes, you might want to use algorithms, for example for feature engineering, that are not implemented in scikit-learn. But perhaps these transformations still have free parameters to estimate. What to do? \n",
    "\n",
    "`scikit-learn` classes inherit from certain base classes that make it easy to implement your own objects. Below is an example I wrote for a machine learning model on time series, where I wanted to re-bin the time series in different ways and and optimize the rebinning factor with respect to the classification afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class RebinTimeseries(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, n=4, method=\"average\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters\n",
    "\n",
    "        :param n: number of samples to bin\n",
    "        :param method: \"average\" or \"sum\" the samples within a bin?\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n ## save number of bins to average together\n",
    "        self.method = method\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self,X):\n",
    "        \"\"\"\n",
    "        I don't really need a fit method!\n",
    "        \"\"\"\n",
    "        \n",
    "        ## set number of light curves (L) and \n",
    "        ## number of samples per light curve (k)\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "        self.L, self.K = X.shape\n",
    "\n",
    "    \n",
    "        ## set the number of binned samples per light curve\n",
    "        K_binned = int(self.K/self.n)\n",
    "        \n",
    "        ## if the number of samples in the original light curve\n",
    "        ## is not divisible by n, then chop off the last few samples of \n",
    "        ## the light curve to make it divisible\n",
    "        #print(\"X shape: \" + str(X.shape))\n",
    "\n",
    "        if K_binned*self.n < self.K:\n",
    "            X = X[:,:self.n*K_binned]\n",
    "        \n",
    "        ## the array for the new, binned light curves\n",
    "        X_binned = np.zeros((self.L, K_binned))\n",
    "        \n",
    "        if self.method in [\"average\", \"mean\"]:\n",
    "            method = np.mean\n",
    "        elif self.method == \"sum\":\n",
    "            method = np.sum\n",
    "        else:\n",
    "            raise Exception(\"Method not recognized!\")\n",
    "        \n",
    "        #print(\"X shape: \" + str(X.shape))\n",
    "        #print(\"L: \" + str(self.L))\n",
    "        for i in xrange(self.L):\n",
    "            t_reshape = X[i,:].reshape((K_binned, self.n))\n",
    "            X_binned[i,:] = method(t_reshape, axis=1)\n",
    "        \n",
    "        return X_binned\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "\n",
    "        self.fit(X)\n",
    "        X_binned = self.transform(X)\n",
    "\n",
    "        return X_binned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the important things about writing transformer objects for use in scikit-learn:\n",
    "* The class must have the following methods:\n",
    "    - `fit`: fit your training data\n",
    "    - `transform`: transform your training data into the new representation\n",
    "    - `predict`: predict new examples\n",
    "    - `score`: score predictions\n",
    "    - `fit_transform` is optional (I think)\n",
    "* The `__init__` method *only* sets up parameters. Don't put any relevant code in there (this is convention more than anything else, but it's a good one to follow!)\n",
    "* The `fit` method is always called in a `Pipeline` object (either on its own or as part of `fit_transform`). It usually modifies the internal state of the object, so returning `self` (i.e. the object itself) is usually fine.\n",
    "* For transformer objects, which don't need scoring and prediction methods, you can just return `pass` as above.\n",
    "\n",
    "**Exercise 8**: Last time, you learned that the SDSS photometric classifier uses a single hard cut to separate stars and galaxies in imaging data:\n",
    "$$\\mathtt{psfMag} - \\mathtt{cmodelMag} \\gt 0.145,$$\n",
    "sources that satisfy this criteria are considered galaxies.\n",
    "\n",
    "* Implement an object that takes $\\mathtt{psfMag}$ and $\\mathtt{cmodelMag}$ as inputs and has a free parameter `s` that sets the value above which a source is considered a galaxy. \n",
    "* Implement a `transform` methods that returns a single binary feature that is one if $$\\mathtt{psfMag} - \\mathtt{cmodelMag} \\gt p$$ and zero otherwise. \n",
    "* Add this feature to your optimized set of features consisting of either the PCA or your alternative representation, and run a random forest classifier on both. Run a CV on all components involved.\n",
    "\n",
    "*Hint*: $\\mathtt{psfMag}$ and $\\mathtt{cmodelMag}$ are the first and the last column in your feature vector, respectively.\n",
    "\n",
    "*Hint*: You can use [`FeatureUnion`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion) to combine the outputs of two transformers in a single data set. (Note that using pipeline with all three will *chain* them, rather than compute the feature union, followed by a classifier). You can input your `FeatureUnion` object into `Pipeline`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PSFMagThreshold(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, p=1.45,):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        p : float\n",
    "            The threshold for the magnitude - model magnitude\n",
    "        \"\"\"\n",
    "\n",
    "        self.p = p # store parameter in object\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self,X):\n",
    "        \"\"\"\n",
    "        I don't really need a fit method!\n",
    "        \"\"\"\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "\n",
    "        # extract relevant columns\n",
    "        psfmag = X[:,0]\n",
    "        c_psfmag = X[:,-1]\n",
    "        \n",
    "        # compute difference\n",
    "        d_psfmag = psfmag - c_psfmag\n",
    "        \n",
    "        # make a 1D array of length N\n",
    "        X_new = np.zeros(X.shape[0])\n",
    "        \n",
    "        X_new[d_psfmag > self.p] = 1.0\n",
    "        \n",
    "        # IMPORTANT: Your output vector must be a COLUMN vector\n",
    "        # You can achieve this with the numpy function atleast_2D()\n",
    "        # and the numpy function transpose()\n",
    "        return np.atleast_2d(X_new).T\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "\n",
    "        self.fit(X)\n",
    "        X_new = self.transform(X)\n",
    "\n",
    "        return X_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt = PSFMagThreshold(p=1.45)\n",
    "X_pt = pt.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a feature set that combines this feature with the PCA features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "transformers = [(\"pca\", PCA(n_components=2)),\n",
    "                (\"pt\", PSFMagThreshold(p=1.45))]\n",
    "\n",
    "feat_union = FeatureUnion(transformers)\n",
    "\n",
    "X_transformed = feat_union.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9725\n",
      "Best parameter set: {'feats__pca__n_components': 4, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 100, 'feats__pt__p': 0.5}\n",
      "Validation score: 0.961428571429\n"
     ]
    }
   ],
   "source": [
    "# combine the \n",
    "transformers = [(\"pca\", PCA()),\n",
    "                (\"pt\", PSFMagThreshold(p=1.45))]\n",
    "\n",
    "feat_union = FeatureUnion(transformers)\n",
    "\n",
    "estimators = [(\"feats\", feat_union),\n",
    "        (\"clf\", RandomForestClassifier())]\n",
    "\n",
    "pipe_c = Pipeline(estimators)\n",
    "\n",
    "# make the parameter set\n",
    "params = dict(feats__pca__n_components=[2, 4, 6, 8],\n",
    "              feats__pt__p=[0.5, 0.9, 1.45, 2.0],\n",
    "              clf__n_estimators=[10, 100, 300],\n",
    "              clf__min_samples_leaf=[1,10])\n",
    "\n",
    "# perform the grid search\n",
    "grid_search_c = GridSearchCV(pipe_c, param_grid=params)\n",
    "grid_search_c.fit(X_train_new, y_train_new)\n",
    "\n",
    "# print validation score\n",
    "print(\"Best score: \" + str(grid_search_c.best_score_))\n",
    "print(\"Best parameter set: \" + str(grid_search_c.best_params_))\n",
    "print(\"Validation score: \" + str(grid_search_c.score(X_val, y_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing The Right Scoring Function\n",
    "\n",
    "As a standard, the algorithms in `scikit-learn` use `accuracy` to score results. The accuracy is basically the raw fraction of correctly classified samples in your validation or test set. \n",
    "\n",
    "**Question**: Is this scoring function always the best method to use? Why (not)? Can you think of alternatives to use?\n",
    "\n",
    "Let's make a heavily biased data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all stars\n",
    "star_ind = np.argwhere(y == b\"STAR\").T[0]\n",
    "# all galaxies\n",
    "galaxy_ind = np.argwhere(y == b\"GALAXY\").T[0]\n",
    "\n",
    "np.random.seed(100)\n",
    "# new array with much fewer stars\n",
    "star_ind_new = np.random.choice(star_ind, replace=False, size=int(len(star_ind)/80.0))\n",
    "\n",
    "X_new = np.vstack((X[galaxy_ind], X[star_ind_new]))\n",
    "y_new = np.hstack((y[galaxy_ind], y[star_ind_new]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now made a really imbalanced data set with many galaxies and only a few stars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4652\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(y_new[y_new == b\"GALAXY\"]))\n",
    "print(len(y_new[y_new == b\"STAR\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10**: Run a logistic regression classifier on this data, for a very low regularization (0.0001) and a very large regularization (10000) parameter. Print the accuracy and a confusion matrix of the results for each run. How many mis-classified samples are in each? Where do the mis-classifications end up? If you were to run a cross validation on this, could you be sure to get a good model? Why (not)?\n",
    "\n",
    "*Hint*: Our imbalanced class, the one we're interested in, is the  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for C = 0 is 0.9866\n",
      "[[1397    0]\n",
      " [  19    0]]\n",
      "The accuracy score for C = 10000 is 0.9859\n",
      "[[1392    5]\n",
      " [  15    4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_new, y_new, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 20)\n",
    "\n",
    "C_all = [0.0001, 10000]\n",
    "\n",
    "for C in C_all:\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=C)\n",
    "\n",
    "    lr.fit(X_train2, y_train2)\n",
    "    y_pred = lr.predict(X_test2)\n",
    "\n",
    "    print(\"The accuracy score for C = %i is %.4f\"%(C, accuracy_score(y_test2, y_pred)))\n",
    "\n",
    "    cm = confusion_matrix(y_test2, y_pred, labels=np.unique(y))\n",
    "    print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11**: Take a look at the [metrics](http://scikit-learn.org/stable/modules/model_evaluation.html) implemented for model evaluation in `scikit-learn`, in particular the different versions of the [F1 score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score). Is there a metric that may be more suited to the task above? Which one? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for C = 0 is 0.9866\n",
      "The F1 score for C = 0.00010 is 0.0000\n",
      "[[1397    0]\n",
      " [  19    0]]\n",
      "The accuracy score for C = 10000 is 0.9859\n",
      "The F1 score for C = 10000.00000 is 0.2857\n",
      "[[1392    5]\n",
      " [  15    4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for C in C_all:\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l2', C=C)\n",
    "\n",
    "    lr.fit(X_train2, y_train2)\n",
    "    y_pred = lr.predict(X_test2)\n",
    "\n",
    "    print(\"The accuracy score for C = %i is %.4f\"%(C, accuracy_score(y_test2, y_pred)))\n",
    "    print(\"The F1 score for C = %.5f is %.4f\"%(C, f1_score(y_test2, y_pred, \n",
    "                                                         pos_label=b\"STAR\", \n",
    "                                                         average=\"binary\")))\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_test2, y_pred, labels=np.unique(y))\n",
    "    print(cm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the accuracy for the model that mis-classifies all stars ends up being higher than the accuracy for the model that only mis-classifies some of them (admittedly, still more than you'd want). So when doing cross-validation, you're quite likely to end up with a model that mis-classifies all your samples from the rare class into the more common class.  \n",
    "If the rare class is actually one that you care about (say, gravitational wave triggers), then this is *very* bad behaviour.\n",
    "\n",
    "The F-score, conversely, is zero for stars with the small regularization parameter (since there are no stars in this group), and not very high, but higher for the large regularization parameter. This is more what we'd like to see if we're interested in the rare class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
